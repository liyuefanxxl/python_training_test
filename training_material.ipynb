{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X = iris.data\n",
    "iris_y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of k-Nearest Neighbors is intuitive. For a certain point, calculate the Euclidean distance from all rest points, and rank them from the nearest to the farthest. Then choose the nearest k neighbor points as sample. In these samples, each point belongs to a certain discrete group, and the group which appears most of the times in this sample will be considered as the category estimation for our chosen point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "# from sklearn.neighbors import KNeighborsRegressor is for continuous y (target) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsClassifier in module sklearn.neighbors.classification:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors.base.NeighborsBase, sklearn.neighbors.base.KNeighborsMixin, sklearn.neighbors.base.SupervisedIntegerMixin, sklearn.base.ClassifierMixin)\n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, optional (default = 5)\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : str or callable, optional (default = 'uniform')\n",
      " |      weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, optional (default = 30)\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : integer, optional (default = 2)\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : string or callable, default 'minkowski'\n",
      " |      the distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. See the documentation of the DistanceMetric class for a\n",
      " |      list of available metrics.\n",
      " |  \n",
      " |  metric_params : dict, optional (default = None)\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.66666667 0.33333333]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier\n",
      " |  KNeighborsRegressor\n",
      " |  RadiusNeighborsRegressor\n",
      " |  NearestNeighbors\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors.base.NeighborsBase\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.neighbors.base.KNeighborsMixin\n",
      " |      sklearn.neighbors.base.SupervisedIntegerMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape [n_samples] or [n_samples, n_outputs]\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Finds the K-neighbors of a point.\n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors to get (default is the value\n",
      " |          passed to the constructor).\n",
      " |      \n",
      " |      return_distance : boolean, optional. Defaults to True.\n",
      " |          If False, distances will not be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dist : array\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True\n",
      " |      \n",
      " |      ind : array\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NeighborsClassifier\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Computes the (weighted) graph of k-Neighbors for points in X\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors for each sample.\n",
      " |          (default is value passed to the constructor).\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, optional\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are Euclidean distance between points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse matrix in CSR format, shape = [n_samples, n_samples_fit]\n",
      " |          n_samples_fit is the number of samples in the fitted data\n",
      " |          A[i, j] is assigned the weight of edge that connects i to j.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.SupervisedIntegerMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model using X as training data and y as target values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, BallTree, KDTree}\n",
      " |          Training data. If array or matrix, shape [n_samples, n_features],\n",
      " |          or [n_samples, n_samples] if metric='precomputed'.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix}\n",
      " |          Target values of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module sklearn.neighbors.base:\n",
      "\n",
      "fit(self, X, y)\n",
      "    Fit the model using X as training data and y as target values\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix, BallTree, KDTree}\n",
      "        Training data. If array or matrix, shape [n_samples, n_features],\n",
      "        or [n_samples, n_samples] if metric='precomputed'.\n",
      "    \n",
      "    y : {array-like, sparse matrix}\n",
      "        Target values of shape = [n_samples] or [n_samples, n_outputs]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KNeighborsClassifier.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to randomly split training and testing data, construct indices\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(iris_X.shape[0])\n",
    "\n",
    "# leave 10 data points aside for testing\n",
    "iris_X_train = iris_X[indices[:-20]]\n",
    "iris_y_train = iris_y[indices[:-20]]\n",
    "iris_X_test = iris_X[indices[-20:]]\n",
    "iris_y_test = iris_y[indices[-20:]]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train,iris_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(iris_y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = knn.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_knn==iris_y_test)/len(pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classification\n",
    "\n",
    "$$ y = sigmoid(X\\beta - offset) + \\epsilon = \\frac{1}{1+\\exp(-X\\beta+offset)}+\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model.logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(solver='lbfgs',C=1e5,multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli368\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(iris_X_train,iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = log.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_log==iris_y_test)/len(pred_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here fit_intercept is default to be true, but should pay attention if X already has constant column in it, remember to set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(iris_X_train[:,:2],iris_y_train)\n",
    "x_min, x_max = iris_X_test[:, 0].min() - .5, iris_X_test[:, 0].max() + .5\n",
    "y_min, y_max = iris_X_test[:, 1].min() - .5, iris_X_test[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(12, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(iris_X_test[:, 0], iris_X_test[:, 1], c=iris_y_test, edgecolors='k', cmap=plt.cm.Paired);\n",
    "plt.xlabel('Sepal length');\n",
    "plt.ylabel('Sepal width');\n",
    "\n",
    "plt.xlim(xx.min(), xx.max());\n",
    "plt.ylim(yy.min(), yy.max());\n",
    "plt.xticks(());\n",
    "plt.yticks(());\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log2 = logreg.predict(iris_X_test[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_log2==iris_y_test)/len(pred_log2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is important for avoid overfitting. For example, in polynomial regression,\n",
    "\n",
    "$$\\theta = y \\cdot X(X^T X + \\alpha I)^{-1}$$\n",
    "\n",
    "Choose the appropriate $\\alpha$ to change the order of regularization.\n",
    "\n",
    "More generally, we have $L_p$ regularizer: $(\\Sigma_{i} |(\\theta_i)|^p)^{\\frac{1}{p}}$\n",
    "\n",
    "For p=1, which is known as Lasso, the parameters finally chosen will be as sparse as possible (a good news for high-dimension problems).\n",
    "\n",
    "![title](Regularization.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ravel:\n",
      "\n",
      "ravel(...) method of numpy.ndarray instance\n",
      "    a.ravel([order])\n",
      "    \n",
      "    Return a flattened array.\n",
      "    \n",
      "    Refer to `numpy.ravel` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.ravel : equivalent function\n",
      "    \n",
      "    ndarray.flat : a flat iterator on the array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xx.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CClass in module numpy.lib.index_tricks object:\n",
      "\n",
      "class CClass(AxisConcatenator)\n",
      " |  Translates slice objects to concatenation along the second axis.\n",
      " |  \n",
      " |  This is short-hand for ``np.r_['-1,2,0', index expression]``, which is\n",
      " |  useful because of its common occurrence. In particular, arrays will be\n",
      " |  stacked along their last axis after being upgraded to at least 2-D with\n",
      " |  1's post-pended to the shape (column vectors made out of 1-D arrays).\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      " |  r_ : For more detailed documentation.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> np.c_[np.array([1,2,3]), np.array([4,5,6])]\n",
      " |  array([[1, 4],\n",
      " |         [2, 5],\n",
      " |         [3, 6]])\n",
      " |  >>> np.c_[np.array([[1,2,3]]), 0, 0, np.array([[4,5,6]])]\n",
      " |  array([[1, 2, 3, 0, 0, 4, 5, 6]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CClass\n",
      " |      AxisConcatenator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from AxisConcatenator:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from AxisConcatenator:\n",
      " |  \n",
      " |  concatenate(...)\n",
      " |      concatenate((a1, a2, ...), axis=0, out=None)\n",
      " |      \n",
      " |      Join a sequence of arrays along an existing axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a1, a2, ... : sequence of array_like\n",
      " |          The arrays must have the same shape, except in the dimension\n",
      " |          corresponding to `axis` (the first, by default).\n",
      " |      axis : int, optional\n",
      " |          The axis along which the arrays will be joined.  Default is 0.\n",
      " |      out : ndarray, optional\n",
      " |          If provided, the destination to place the result. The shape must be\n",
      " |          correct, matching that of what concatenate would have returned if no\n",
      " |          out argument were specified.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ndarray\n",
      " |          The concatenated array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ma.concatenate : Concatenate function that preserves input masks.\n",
      " |      array_split : Split an array into multiple sub-arrays of equal or\n",
      " |                    near-equal size.\n",
      " |      split : Split array into a list of multiple sub-arrays of equal size.\n",
      " |      hsplit : Split array into multiple sub-arrays horizontally (column wise)\n",
      " |      vsplit : Split array into multiple sub-arrays vertically (row wise)\n",
      " |      dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      " |      stack : Stack a sequence of arrays along a new axis.\n",
      " |      hstack : Stack arrays in sequence horizontally (column wise)\n",
      " |      vstack : Stack arrays in sequence vertically (row wise)\n",
      " |      dstack : Stack arrays in sequence depth wise (along third dimension)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When one or more of the arrays to be concatenated is a MaskedArray,\n",
      " |      this function will return a MaskedArray object instead of an ndarray,\n",
      " |      but the input masks are *not* preserved. In cases where a MaskedArray\n",
      " |      is expected as input, use the ma.concatenate function from the masked\n",
      " |      array module instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([[1, 2], [3, 4]])\n",
      " |      >>> b = np.array([[5, 6]])\n",
      " |      >>> np.concatenate((a, b), axis=0)\n",
      " |      array([[1, 2],\n",
      " |             [3, 4],\n",
      " |             [5, 6]])\n",
      " |      >>> np.concatenate((a, b.T), axis=1)\n",
      " |      array([[1, 2, 5],\n",
      " |             [3, 4, 6]])\n",
      " |      \n",
      " |      This function will not preserve masking of MaskedArray inputs.\n",
      " |      \n",
      " |      >>> a = np.ma.arange(3)\n",
      " |      >>> a[1] = np.ma.masked\n",
      " |      >>> b = np.arange(2, 5)\n",
      " |      >>> a\n",
      " |      masked_array(data = [0 -- 2],\n",
      " |                   mask = [False  True False],\n",
      " |             fill_value = 999999)\n",
      " |      >>> b\n",
      " |      array([2, 3, 4])\n",
      " |      >>> np.concatenate([a, b])\n",
      " |      masked_array(data = [0 1 2 2 3 4],\n",
      " |                   mask = False,\n",
      " |             fill_value = 999999)\n",
      " |      >>> np.ma.concatenate([a, b])\n",
      " |      masked_array(data = [0 -- 2 2 3 4],\n",
      " |                   mask = [False  True False False False False],\n",
      " |             fill_value = 999999)\n",
      " |  \n",
      " |  makemat = class matrix(numpy.ndarray)\n",
      " |   |  matrix(data, dtype=None, copy=True)\n",
      " |   |  \n",
      " |   |  Returns a matrix from an array-like object, or from a string of data.\n",
      " |   |  A matrix is a specialized 2-D array that retains its 2-D nature\n",
      " |   |  through operations.  It has certain special operators, such as ``*``\n",
      " |   |  (matrix multiplication) and ``**`` (matrix power).\n",
      " |   |  \n",
      " |   |  Parameters\n",
      " |   |  ----------\n",
      " |   |  data : array_like or string\n",
      " |   |     If `data` is a string, it is interpreted as a matrix with commas\n",
      " |   |     or spaces separating columns, and semicolons separating rows.\n",
      " |   |  dtype : data-type\n",
      " |   |     Data-type of the output matrix.\n",
      " |   |  copy : bool\n",
      " |   |     If `data` is already an `ndarray`, then this flag determines\n",
      " |   |     whether the data is copied (the default), or whether a view is\n",
      " |   |     constructed.\n",
      " |   |  \n",
      " |   |  See Also\n",
      " |   |  --------\n",
      " |   |  array\n",
      " |   |  \n",
      " |   |  Examples\n",
      " |   |  --------\n",
      " |   |  >>> a = np.matrix('1 2; 3 4')\n",
      " |   |  >>> print(a)\n",
      " |   |  [[1 2]\n",
      " |   |   [3 4]]\n",
      " |   |  \n",
      " |   |  >>> np.matrix([[1, 2], [3, 4]])\n",
      " |   |  matrix([[1, 2],\n",
      " |   |          [3, 4]])\n",
      " |   |  \n",
      " |   |  Method resolution order:\n",
      " |   |      matrix\n",
      " |   |      numpy.ndarray\n",
      " |   |      builtins.object\n",
      " |   |  \n",
      " |   |  Methods defined here:\n",
      " |   |  \n",
      " |   |  __array_finalize__(self, obj)\n",
      " |   |      None.\n",
      " |   |  \n",
      " |   |  __getitem__(self, index)\n",
      " |   |      Return self[key].\n",
      " |   |  \n",
      " |   |  __imul__(self, other)\n",
      " |   |      Return self*=value.\n",
      " |   |  \n",
      " |   |  __ipow__(self, other)\n",
      " |   |      Return self**=value.\n",
      " |   |  \n",
      " |   |  __mul__(self, other)\n",
      " |   |      Return self*value.\n",
      " |   |  \n",
      " |   |  __pow__(self, other)\n",
      " |   |      Return pow(self, value, mod).\n",
      " |   |  \n",
      " |   |  __rmul__(self, other)\n",
      " |   |      Return value*self.\n",
      " |   |  \n",
      " |   |  __rpow__(self, other)\n",
      " |   |      Return pow(value, self, mod).\n",
      " |   |  \n",
      " |   |  all(self, axis=None, out=None)\n",
      " |   |      Test whether all matrix elements along a given axis evaluate to True.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      See `numpy.all` for complete descriptions\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.all\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.all`, but it returns a `matrix` object.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> y = x[0]; y\n",
      " |   |      matrix([[0, 1, 2, 3]])\n",
      " |   |      >>> (x == y)\n",
      " |   |      matrix([[ True,  True,  True,  True],\n",
      " |   |              [False, False, False, False],\n",
      " |   |              [False, False, False, False]])\n",
      " |   |      >>> (x == y).all()\n",
      " |   |      False\n",
      " |   |      >>> (x == y).all(0)\n",
      " |   |      matrix([[False, False, False, False]])\n",
      " |   |      >>> (x == y).all(1)\n",
      " |   |      matrix([[ True],\n",
      " |   |              [False],\n",
      " |   |              [False]])\n",
      " |   |  \n",
      " |   |  any(self, axis=None, out=None)\n",
      " |   |      Test whether any array element along a given axis evaluates to True.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.any` for full documentation.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      axis : int, optional\n",
      " |   |          Axis along which logical OR is performed\n",
      " |   |      out : ndarray, optional\n",
      " |   |          Output to existing array instead of creating new one, must have\n",
      " |   |          same shape as expected output\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |          any : bool, ndarray\n",
      " |   |              Returns a single bool if `axis` is ``None``; otherwise,\n",
      " |   |              returns `ndarray`\n",
      " |   |  \n",
      " |   |  argmax(self, axis=None, out=None)\n",
      " |   |      Indexes of the maximum values along an axis.\n",
      " |   |      \n",
      " |   |      Return the indexes of the first occurrences of the maximum values\n",
      " |   |      along the specified axis.  If axis is None, the index is for the\n",
      " |   |      flattened matrix.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      See `numpy.argmax` for complete descriptions\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.argmax\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.argmax`, but returns a `matrix` object\n",
      " |   |      where `ndarray.argmax` would return an `ndarray`.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.argmax()\n",
      " |   |      11\n",
      " |   |      >>> x.argmax(0)\n",
      " |   |      matrix([[2, 2, 2, 2]])\n",
      " |   |      >>> x.argmax(1)\n",
      " |   |      matrix([[3],\n",
      " |   |              [3],\n",
      " |   |              [3]])\n",
      " |   |  \n",
      " |   |  argmin(self, axis=None, out=None)\n",
      " |   |      Indexes of the minimum values along an axis.\n",
      " |   |      \n",
      " |   |      Return the indexes of the first occurrences of the minimum values\n",
      " |   |      along the specified axis.  If axis is None, the index is for the\n",
      " |   |      flattened matrix.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      See `numpy.argmin` for complete descriptions.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.argmin\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.argmin`, but returns a `matrix` object\n",
      " |   |      where `ndarray.argmin` would return an `ndarray`.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = -np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[  0,  -1,  -2,  -3],\n",
      " |   |              [ -4,  -5,  -6,  -7],\n",
      " |   |              [ -8,  -9, -10, -11]])\n",
      " |   |      >>> x.argmin()\n",
      " |   |      11\n",
      " |   |      >>> x.argmin(0)\n",
      " |   |      matrix([[2, 2, 2, 2]])\n",
      " |   |      >>> x.argmin(1)\n",
      " |   |      matrix([[3],\n",
      " |   |              [3],\n",
      " |   |              [3]])\n",
      " |   |  \n",
      " |   |  flatten(self, order='C')\n",
      " |   |      Return a flattened copy of the matrix.\n",
      " |   |      \n",
      " |   |      All `N` elements of the matrix are placed into a single row.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |   |          'C' means to flatten in row-major (C-style) order. 'F' means to\n",
      " |   |          flatten in column-major (Fortran-style) order. 'A' means to\n",
      " |   |          flatten in column-major order if `m` is Fortran *contiguous* in\n",
      " |   |          memory, row-major order otherwise. 'K' means to flatten `m` in\n",
      " |   |          the order the elements occur in memory. The default is 'C'.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      y : matrix\n",
      " |   |          A copy of the matrix, flattened to a `(1, N)` matrix where `N`\n",
      " |   |          is the number of elements in the original matrix.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      ravel : Return a flattened array.\n",
      " |   |      flat : A 1-D flat iterator over the matrix.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> m = np.matrix([[1,2], [3,4]])\n",
      " |   |      >>> m.flatten()\n",
      " |   |      matrix([[1, 2, 3, 4]])\n",
      " |   |      >>> m.flatten('F')\n",
      " |   |      matrix([[1, 3, 2, 4]])\n",
      " |   |  \n",
      " |   |  getA(self)\n",
      " |   |      Return `self` as an `ndarray` object.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.asarray(self)``.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : ndarray\n",
      " |   |          `self` as an `ndarray`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.getA()\n",
      " |   |      array([[ 0,  1,  2,  3],\n",
      " |   |             [ 4,  5,  6,  7],\n",
      " |   |             [ 8,  9, 10, 11]])\n",
      " |   |  \n",
      " |   |  getA1(self)\n",
      " |   |      Return `self` as a flattened `ndarray`.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.asarray(x).ravel()``\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : ndarray\n",
      " |   |          `self`, 1-D, as an `ndarray`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.getA1()\n",
      " |   |      array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      " |   |  \n",
      " |   |  getH(self)\n",
      " |   |      Returns the (complex) conjugate transpose of `self`.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.transpose(self)`` if `self` is real-valued.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          complex conjugate transpose of `self`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4)))\n",
      " |   |      >>> z = x - 1j*x; z\n",
      " |   |      matrix([[  0. +0.j,   1. -1.j,   2. -2.j,   3. -3.j],\n",
      " |   |              [  4. -4.j,   5. -5.j,   6. -6.j,   7. -7.j],\n",
      " |   |              [  8. -8.j,   9. -9.j,  10.-10.j,  11.-11.j]])\n",
      " |   |      >>> z.getH()\n",
      " |   |      matrix([[  0. +0.j,   4. +4.j,   8. +8.j],\n",
      " |   |              [  1. +1.j,   5. +5.j,   9. +9.j],\n",
      " |   |              [  2. +2.j,   6. +6.j,  10.+10.j],\n",
      " |   |              [  3. +3.j,   7. +7.j,  11.+11.j]])\n",
      " |   |  \n",
      " |   |  getI(self)\n",
      " |   |      Returns the (multiplicative) inverse of invertible `self`.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          If `self` is non-singular, `ret` is such that ``ret * self`` ==\n",
      " |   |          ``self * ret`` == ``np.matrix(np.eye(self[0,:].size)`` all return\n",
      " |   |          ``True``.\n",
      " |   |      \n",
      " |   |      Raises\n",
      " |   |      ------\n",
      " |   |      numpy.linalg.LinAlgError: Singular matrix\n",
      " |   |          If `self` is singular.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      linalg.inv\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> m = np.matrix('[1, 2; 3, 4]'); m\n",
      " |   |      matrix([[1, 2],\n",
      " |   |              [3, 4]])\n",
      " |   |      >>> m.getI()\n",
      " |   |      matrix([[-2. ,  1. ],\n",
      " |   |              [ 1.5, -0.5]])\n",
      " |   |      >>> m.getI() * m\n",
      " |   |      matrix([[ 1.,  0.],\n",
      " |   |              [ 0.,  1.]])\n",
      " |   |  \n",
      " |   |  getT(self)\n",
      " |   |      Returns the transpose of the matrix.\n",
      " |   |      \n",
      " |   |      Does *not* conjugate!  For the complex conjugate transpose, use ``.H``.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          The (non-conjugated) transpose of the matrix.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      transpose, getH\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> m = np.matrix('[1, 2; 3, 4]')\n",
      " |   |      >>> m\n",
      " |   |      matrix([[1, 2],\n",
      " |   |              [3, 4]])\n",
      " |   |      >>> m.getT()\n",
      " |   |      matrix([[1, 3],\n",
      " |   |              [2, 4]])\n",
      " |   |  \n",
      " |   |  max(self, axis=None, out=None)\n",
      " |   |      Return the maximum value along an axis.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      See `amax` for complete descriptions\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      amax, ndarray.max\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.max`, but returns a `matrix` object\n",
      " |   |      where `ndarray.max` would return an ndarray.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.max()\n",
      " |   |      11\n",
      " |   |      >>> x.max(0)\n",
      " |   |      matrix([[ 8,  9, 10, 11]])\n",
      " |   |      >>> x.max(1)\n",
      " |   |      matrix([[ 3],\n",
      " |   |              [ 7],\n",
      " |   |              [11]])\n",
      " |   |  \n",
      " |   |  mean(self, axis=None, dtype=None, out=None)\n",
      " |   |      Returns the average of the matrix elements along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.mean` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.mean\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Same as `ndarray.mean` except that, where that returns an `ndarray`,\n",
      " |   |      this returns a `matrix` object.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      " |   |      >>> x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.mean()\n",
      " |   |      5.5\n",
      " |   |      >>> x.mean(0)\n",
      " |   |      matrix([[ 4.,  5.,  6.,  7.]])\n",
      " |   |      >>> x.mean(1)\n",
      " |   |      matrix([[ 1.5],\n",
      " |   |              [ 5.5],\n",
      " |   |              [ 9.5]])\n",
      " |   |  \n",
      " |   |  min(self, axis=None, out=None)\n",
      " |   |      Return the minimum value along an axis.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      See `amin` for complete descriptions.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      amin, ndarray.min\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.min`, but returns a `matrix` object\n",
      " |   |      where `ndarray.min` would return an ndarray.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = -np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[  0,  -1,  -2,  -3],\n",
      " |   |              [ -4,  -5,  -6,  -7],\n",
      " |   |              [ -8,  -9, -10, -11]])\n",
      " |   |      >>> x.min()\n",
      " |   |      -11\n",
      " |   |      >>> x.min(0)\n",
      " |   |      matrix([[ -8,  -9, -10, -11]])\n",
      " |   |      >>> x.min(1)\n",
      " |   |      matrix([[ -3],\n",
      " |   |              [ -7],\n",
      " |   |              [-11]])\n",
      " |   |  \n",
      " |   |  prod(self, axis=None, dtype=None, out=None)\n",
      " |   |      Return the product of the array elements over the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `prod` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      prod, ndarray.prod\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Same as `ndarray.prod`, except, where that returns an `ndarray`, this\n",
      " |   |      returns a `matrix` object instead.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.prod()\n",
      " |   |      0\n",
      " |   |      >>> x.prod(0)\n",
      " |   |      matrix([[  0,  45, 120, 231]])\n",
      " |   |      >>> x.prod(1)\n",
      " |   |      matrix([[   0],\n",
      " |   |              [ 840],\n",
      " |   |              [7920]])\n",
      " |   |  \n",
      " |   |  ptp(self, axis=None, out=None)\n",
      " |   |      Peak-to-peak (maximum - minimum) value along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.ptp` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.ptp\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Same as `ndarray.ptp`, except, where that would return an `ndarray` object,\n",
      " |   |      this returns a `matrix` object.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.ptp()\n",
      " |   |      11\n",
      " |   |      >>> x.ptp(0)\n",
      " |   |      matrix([[8, 8, 8, 8]])\n",
      " |   |      >>> x.ptp(1)\n",
      " |   |      matrix([[3],\n",
      " |   |              [3],\n",
      " |   |              [3]])\n",
      " |   |  \n",
      " |   |  ravel(self, order='C')\n",
      " |   |      Return a flattened matrix.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.ravel` for more documentation.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |   |          The elements of `m` are read using this index order. 'C' means to\n",
      " |   |          index the elements in C-like order, with the last axis index\n",
      " |   |          changing fastest, back to the first axis index changing slowest.\n",
      " |   |          'F' means to index the elements in Fortran-like index order, with\n",
      " |   |          the first index changing fastest, and the last index changing\n",
      " |   |          slowest. Note that the 'C' and 'F' options take no account of the\n",
      " |   |          memory layout of the underlying array, and only refer to the order\n",
      " |   |          of axis indexing.  'A' means to read the elements in Fortran-like\n",
      " |   |          index order if `m` is Fortran *contiguous* in memory, C-like order\n",
      " |   |          otherwise.  'K' means to read the elements in the order they occur\n",
      " |   |          in memory, except for reversing the data when strides are negative.\n",
      " |   |          By default, 'C' index order is used.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix\n",
      " |   |          Return the matrix flattened to shape `(1, N)` where `N`\n",
      " |   |          is the number of elements in the original matrix.\n",
      " |   |          A copy is made only if necessary.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      matrix.flatten : returns a similar output matrix but always a copy\n",
      " |   |      matrix.flat : a flat iterator on the array.\n",
      " |   |      numpy.ravel : related function which returns an ndarray\n",
      " |   |  \n",
      " |   |  squeeze(self, axis=None)\n",
      " |   |      Return a possibly reshaped matrix.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.squeeze` for more documentation.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      axis : None or int or tuple of ints, optional\n",
      " |   |          Selects a subset of the single-dimensional entries in the shape.\n",
      " |   |          If an axis is selected with shape entry greater than one,\n",
      " |   |          an error is raised.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      squeezed : matrix\n",
      " |   |          The matrix, but as a (1, N) matrix if it had shape (N, 1).\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.squeeze : related function\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      If `m` has a single column then that column is returned\n",
      " |   |      as the single row of a matrix.  Otherwise `m` is returned.\n",
      " |   |      The returned matrix is always either `m` itself or a view into `m`.\n",
      " |   |      Supplying an axis keyword argument will not affect the returned matrix\n",
      " |   |      but it may cause an error to be raised.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> c = np.matrix([[1], [2]])\n",
      " |   |      >>> c\n",
      " |   |      matrix([[1],\n",
      " |   |              [2]])\n",
      " |   |      >>> c.squeeze()\n",
      " |   |      matrix([[1, 2]])\n",
      " |   |      >>> r = c.T\n",
      " |   |      >>> r\n",
      " |   |      matrix([[1, 2]])\n",
      " |   |      >>> r.squeeze()\n",
      " |   |      matrix([[1, 2]])\n",
      " |   |      >>> m = np.matrix([[1, 2], [3, 4]])\n",
      " |   |      >>> m.squeeze()\n",
      " |   |      matrix([[1, 2],\n",
      " |   |              [3, 4]])\n",
      " |   |  \n",
      " |   |  std(self, axis=None, dtype=None, out=None, ddof=0)\n",
      " |   |      Return the standard deviation of the array elements along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.std` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.std\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.std`, except that where an `ndarray` would\n",
      " |   |      be returned, a `matrix` object is returned instead.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      " |   |      >>> x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.std()\n",
      " |   |      3.4520525295346629\n",
      " |   |      >>> x.std(0)\n",
      " |   |      matrix([[ 3.26598632,  3.26598632,  3.26598632,  3.26598632]])\n",
      " |   |      >>> x.std(1)\n",
      " |   |      matrix([[ 1.11803399],\n",
      " |   |              [ 1.11803399],\n",
      " |   |              [ 1.11803399]])\n",
      " |   |  \n",
      " |   |  sum(self, axis=None, dtype=None, out=None)\n",
      " |   |      Returns the sum of the matrix elements, along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.sum` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.sum\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.sum`, except that where an `ndarray` would\n",
      " |   |      be returned, a `matrix` object is returned instead.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix([[1, 2], [4, 3]])\n",
      " |   |      >>> x.sum()\n",
      " |   |      10\n",
      " |   |      >>> x.sum(axis=1)\n",
      " |   |      matrix([[3],\n",
      " |   |              [7]])\n",
      " |   |      >>> x.sum(axis=1, dtype='float')\n",
      " |   |      matrix([[ 3.],\n",
      " |   |              [ 7.]])\n",
      " |   |      >>> out = np.zeros((1, 2), dtype='float')\n",
      " |   |      >>> x.sum(axis=1, dtype='float', out=out)\n",
      " |   |      matrix([[ 3.],\n",
      " |   |              [ 7.]])\n",
      " |   |  \n",
      " |   |  tolist(self)\n",
      " |   |      Return the matrix as a (possibly nested) list.\n",
      " |   |      \n",
      " |   |      See `ndarray.tolist` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      ndarray.tolist\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.tolist()\n",
      " |   |      [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]\n",
      " |   |  \n",
      " |   |  var(self, axis=None, dtype=None, out=None, ddof=0)\n",
      " |   |      Returns the variance of the matrix elements, along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.var` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.var\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is the same as `ndarray.var`, except that where an `ndarray` would\n",
      " |   |      be returned, a `matrix` object is returned instead.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      " |   |      >>> x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.var()\n",
      " |   |      11.916666666666666\n",
      " |   |      >>> x.var(0)\n",
      " |   |      matrix([[ 10.66666667,  10.66666667,  10.66666667,  10.66666667]])\n",
      " |   |      >>> x.var(1)\n",
      " |   |      matrix([[ 1.25],\n",
      " |   |              [ 1.25],\n",
      " |   |              [ 1.25]])\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Static methods defined here:\n",
      " |   |  \n",
      " |   |  __new__(subtype, data, dtype=None, copy=True)\n",
      " |   |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Data descriptors defined here:\n",
      " |   |  \n",
      " |   |  A\n",
      " |   |      Return `self` as an `ndarray` object.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.asarray(self)``.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : ndarray\n",
      " |   |          `self` as an `ndarray`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.getA()\n",
      " |   |      array([[ 0,  1,  2,  3],\n",
      " |   |             [ 4,  5,  6,  7],\n",
      " |   |             [ 8,  9, 10, 11]])\n",
      " |   |  \n",
      " |   |  A1\n",
      " |   |      Return `self` as a flattened `ndarray`.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.asarray(x).ravel()``\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : ndarray\n",
      " |   |          `self`, 1-D, as an `ndarray`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      " |   |      matrix([[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]])\n",
      " |   |      >>> x.getA1()\n",
      " |   |      array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      " |   |  \n",
      " |   |  H\n",
      " |   |      Returns the (complex) conjugate transpose of `self`.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.transpose(self)`` if `self` is real-valued.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          complex conjugate transpose of `self`\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.matrix(np.arange(12).reshape((3,4)))\n",
      " |   |      >>> z = x - 1j*x; z\n",
      " |   |      matrix([[  0. +0.j,   1. -1.j,   2. -2.j,   3. -3.j],\n",
      " |   |              [  4. -4.j,   5. -5.j,   6. -6.j,   7. -7.j],\n",
      " |   |              [  8. -8.j,   9. -9.j,  10.-10.j,  11.-11.j]])\n",
      " |   |      >>> z.getH()\n",
      " |   |      matrix([[  0. +0.j,   4. +4.j,   8. +8.j],\n",
      " |   |              [  1. +1.j,   5. +5.j,   9. +9.j],\n",
      " |   |              [  2. +2.j,   6. +6.j,  10.+10.j],\n",
      " |   |              [  3. +3.j,   7. +7.j,  11.+11.j]])\n",
      " |   |  \n",
      " |   |  I\n",
      " |   |      Returns the (multiplicative) inverse of invertible `self`.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          If `self` is non-singular, `ret` is such that ``ret * self`` ==\n",
      " |   |          ``self * ret`` == ``np.matrix(np.eye(self[0,:].size)`` all return\n",
      " |   |          ``True``.\n",
      " |   |      \n",
      " |   |      Raises\n",
      " |   |      ------\n",
      " |   |      numpy.linalg.LinAlgError: Singular matrix\n",
      " |   |          If `self` is singular.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      linalg.inv\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> m = np.matrix('[1, 2; 3, 4]'); m\n",
      " |   |      matrix([[1, 2],\n",
      " |   |              [3, 4]])\n",
      " |   |      >>> m.getI()\n",
      " |   |      matrix([[-2. ,  1. ],\n",
      " |   |              [ 1.5, -0.5]])\n",
      " |   |      >>> m.getI() * m\n",
      " |   |      matrix([[ 1.,  0.],\n",
      " |   |              [ 0.,  1.]])\n",
      " |   |  \n",
      " |   |  T\n",
      " |   |      Returns the transpose of the matrix.\n",
      " |   |      \n",
      " |   |      Does *not* conjugate!  For the complex conjugate transpose, use ``.H``.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      ret : matrix object\n",
      " |   |          The (non-conjugated) transpose of the matrix.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      transpose, getH\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> m = np.matrix('[1, 2; 3, 4]')\n",
      " |   |      >>> m\n",
      " |   |      matrix([[1, 2],\n",
      " |   |              [3, 4]])\n",
      " |   |      >>> m.getT()\n",
      " |   |      matrix([[1, 3],\n",
      " |   |              [2, 4]])\n",
      " |   |  \n",
      " |   |  __dict__\n",
      " |   |      dictionary for instance variables (if defined)\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Data and other attributes defined here:\n",
      " |   |  \n",
      " |   |  __array_priority__ = 10.0\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Methods inherited from numpy.ndarray:\n",
      " |   |  \n",
      " |   |  __abs__(self, /)\n",
      " |   |      abs(self)\n",
      " |   |  \n",
      " |   |  __add__(self, value, /)\n",
      " |   |      Return self+value.\n",
      " |   |  \n",
      " |   |  __and__(self, value, /)\n",
      " |   |      Return self&value.\n",
      " |   |  \n",
      " |   |  __array__(...)\n",
      " |   |      a.__array__(|dtype) -> reference if type unchanged, copy otherwise.\n",
      " |   |      \n",
      " |   |      Returns either a new reference to self if dtype is not given or a new array\n",
      " |   |      of provided data type if dtype is different from the current dtype of the\n",
      " |   |      array.\n",
      " |   |  \n",
      " |   |  __array_prepare__(...)\n",
      " |   |      a.__array_prepare__(obj) -> Object of same type as ndarray object obj.\n",
      " |   |  \n",
      " |   |  __array_ufunc__(...)\n",
      " |   |  \n",
      " |   |  __array_wrap__(...)\n",
      " |   |      a.__array_wrap__(obj) -> Object of same type as ndarray object a.\n",
      " |   |  \n",
      " |   |  __bool__(self, /)\n",
      " |   |      self != 0\n",
      " |   |  \n",
      " |   |  __complex__(...)\n",
      " |   |  \n",
      " |   |  __contains__(self, key, /)\n",
      " |   |      Return key in self.\n",
      " |   |  \n",
      " |   |  __copy__(...)\n",
      " |   |      a.__copy__()\n",
      " |   |      \n",
      " |   |      Used if :func:`copy.copy` is called on an array. Returns a copy of the array.\n",
      " |   |      \n",
      " |   |      Equivalent to ``a.copy(order='K')``.\n",
      " |   |  \n",
      " |   |  __deepcopy__(...)\n",
      " |   |      a.__deepcopy__(memo, /) -> Deep copy of array.\n",
      " |   |      \n",
      " |   |      Used if :func:`copy.deepcopy` is called on an array.\n",
      " |   |  \n",
      " |   |  __delitem__(self, key, /)\n",
      " |   |      Delete self[key].\n",
      " |   |  \n",
      " |   |  __divmod__(self, value, /)\n",
      " |   |      Return divmod(self, value).\n",
      " |   |  \n",
      " |   |  __eq__(self, value, /)\n",
      " |   |      Return self==value.\n",
      " |   |  \n",
      " |   |  __float__(self, /)\n",
      " |   |      float(self)\n",
      " |   |  \n",
      " |   |  __floordiv__(self, value, /)\n",
      " |   |      Return self//value.\n",
      " |   |  \n",
      " |   |  __format__(...)\n",
      " |   |      default object formatter\n",
      " |   |  \n",
      " |   |  __ge__(self, value, /)\n",
      " |   |      Return self>=value.\n",
      " |   |  \n",
      " |   |  __gt__(self, value, /)\n",
      " |   |      Return self>value.\n",
      " |   |  \n",
      " |   |  __iadd__(self, value, /)\n",
      " |   |      Return self+=value.\n",
      " |   |  \n",
      " |   |  __iand__(self, value, /)\n",
      " |   |      Return self&=value.\n",
      " |   |  \n",
      " |   |  __ifloordiv__(self, value, /)\n",
      " |   |      Return self//=value.\n",
      " |   |  \n",
      " |   |  __ilshift__(self, value, /)\n",
      " |   |      Return self<<=value.\n",
      " |   |  \n",
      " |   |  __imatmul__(self, value, /)\n",
      " |   |      Return self@=value.\n",
      " |   |  \n",
      " |   |  __imod__(self, value, /)\n",
      " |   |      Return self%=value.\n",
      " |   |  \n",
      " |   |  __index__(self, /)\n",
      " |   |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      " |   |  \n",
      " |   |  __int__(self, /)\n",
      " |   |      int(self)\n",
      " |   |  \n",
      " |   |  __invert__(self, /)\n",
      " |   |      ~self\n",
      " |   |  \n",
      " |   |  __ior__(self, value, /)\n",
      " |   |      Return self|=value.\n",
      " |   |  \n",
      " |   |  __irshift__(self, value, /)\n",
      " |   |      Return self>>=value.\n",
      " |   |  \n",
      " |   |  __isub__(self, value, /)\n",
      " |   |      Return self-=value.\n",
      " |   |  \n",
      " |   |  __iter__(self, /)\n",
      " |   |      Implement iter(self).\n",
      " |   |  \n",
      " |   |  __itruediv__(self, value, /)\n",
      " |   |      Return self/=value.\n",
      " |   |  \n",
      " |   |  __ixor__(self, value, /)\n",
      " |   |      Return self^=value.\n",
      " |   |  \n",
      " |   |  __le__(self, value, /)\n",
      " |   |      Return self<=value.\n",
      " |   |  \n",
      " |   |  __len__(self, /)\n",
      " |   |      Return len(self).\n",
      " |   |  \n",
      " |   |  __lshift__(self, value, /)\n",
      " |   |      Return self<<value.\n",
      " |   |  \n",
      " |   |  __lt__(self, value, /)\n",
      " |   |      Return self<value.\n",
      " |   |  \n",
      " |   |  __matmul__(self, value, /)\n",
      " |   |      Return self@value.\n",
      " |   |  \n",
      " |   |  __mod__(self, value, /)\n",
      " |   |      Return self%value.\n",
      " |   |  \n",
      " |   |  __ne__(self, value, /)\n",
      " |   |      Return self!=value.\n",
      " |   |  \n",
      " |   |  __neg__(self, /)\n",
      " |   |      -self\n",
      " |   |  \n",
      " |   |  __or__(self, value, /)\n",
      " |   |      Return self|value.\n",
      " |   |  \n",
      " |   |  __pos__(self, /)\n",
      " |   |      +self\n",
      " |   |  \n",
      " |   |  __radd__(self, value, /)\n",
      " |   |      Return value+self.\n",
      " |   |  \n",
      " |   |  __rand__(self, value, /)\n",
      " |   |      Return value&self.\n",
      " |   |  \n",
      " |   |  __rdivmod__(self, value, /)\n",
      " |   |      Return divmod(value, self).\n",
      " |   |  \n",
      " |   |  __reduce__(...)\n",
      " |   |      a.__reduce__()\n",
      " |   |      \n",
      " |   |      For pickling.\n",
      " |   |  \n",
      " |   |  __repr__(self, /)\n",
      " |   |      Return repr(self).\n",
      " |   |  \n",
      " |   |  __rfloordiv__(self, value, /)\n",
      " |   |      Return value//self.\n",
      " |   |  \n",
      " |   |  __rlshift__(self, value, /)\n",
      " |   |      Return value<<self.\n",
      " |   |  \n",
      " |   |  __rmatmul__(self, value, /)\n",
      " |   |      Return value@self.\n",
      " |   |  \n",
      " |   |  __rmod__(self, value, /)\n",
      " |   |      Return value%self.\n",
      " |   |  \n",
      " |   |  __ror__(self, value, /)\n",
      " |   |      Return value|self.\n",
      " |   |  \n",
      " |   |  __rrshift__(self, value, /)\n",
      " |   |      Return value>>self.\n",
      " |   |  \n",
      " |   |  __rshift__(self, value, /)\n",
      " |   |      Return self>>value.\n",
      " |   |  \n",
      " |   |  __rsub__(self, value, /)\n",
      " |   |      Return value-self.\n",
      " |   |  \n",
      " |   |  __rtruediv__(self, value, /)\n",
      " |   |      Return value/self.\n",
      " |   |  \n",
      " |   |  __rxor__(self, value, /)\n",
      " |   |      Return value^self.\n",
      " |   |  \n",
      " |   |  __setitem__(self, key, value, /)\n",
      " |   |      Set self[key] to value.\n",
      " |   |  \n",
      " |   |  __setstate__(...)\n",
      " |   |      a.__setstate__(state, /)\n",
      " |   |      \n",
      " |   |      For unpickling.\n",
      " |   |      \n",
      " |   |      The `state` argument must be a sequence that contains the following\n",
      " |   |      elements:\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      version : int\n",
      " |   |          optional pickle version. If omitted defaults to 0.\n",
      " |   |      shape : tuple\n",
      " |   |      dtype : data-type\n",
      " |   |      isFortran : bool\n",
      " |   |      rawdata : string or list\n",
      " |   |          a binary string with the data (or a list if 'a' is an object array)\n",
      " |   |  \n",
      " |   |  __sizeof__(...)\n",
      " |   |      __sizeof__() -> int\n",
      " |   |      size of object in memory, in bytes\n",
      " |   |  \n",
      " |   |  __str__(self, /)\n",
      " |   |      Return str(self).\n",
      " |   |  \n",
      " |   |  __sub__(self, value, /)\n",
      " |   |      Return self-value.\n",
      " |   |  \n",
      " |   |  __truediv__(self, value, /)\n",
      " |   |      Return self/value.\n",
      " |   |  \n",
      " |   |  __xor__(self, value, /)\n",
      " |   |      Return self^value.\n",
      " |   |  \n",
      " |   |  argpartition(...)\n",
      " |   |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      " |   |      \n",
      " |   |      Returns the indices that would partition this array.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.argpartition` for full documentation.\n",
      " |   |      \n",
      " |   |      .. versionadded:: 1.8.0\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.argpartition : equivalent function\n",
      " |   |  \n",
      " |   |  argsort(...)\n",
      " |   |      a.argsort(axis=-1, kind='quicksort', order=None)\n",
      " |   |      \n",
      " |   |      Returns the indices that would sort this array.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.argsort` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.argsort : equivalent function\n",
      " |   |  \n",
      " |   |  astype(...)\n",
      " |   |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      " |   |      \n",
      " |   |      Copy of the array, cast to a specified type.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      dtype : str or dtype\n",
      " |   |          Typecode or data-type to which the array is cast.\n",
      " |   |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |   |          Controls the memory layout order of the result.\n",
      " |   |          'C' means C order, 'F' means Fortran order, 'A'\n",
      " |   |          means 'F' order if all the arrays are Fortran contiguous,\n",
      " |   |          'C' order otherwise, and 'K' means as close to the\n",
      " |   |          order the array elements appear in memory as possible.\n",
      " |   |          Default is 'K'.\n",
      " |   |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      " |   |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      " |   |          for backwards compatibility.\n",
      " |   |      \n",
      " |   |            * 'no' means the data types should not be cast at all.\n",
      " |   |            * 'equiv' means only byte-order changes are allowed.\n",
      " |   |            * 'safe' means only casts which can preserve values are allowed.\n",
      " |   |            * 'same_kind' means only safe casts or casts within a kind,\n",
      " |   |              like float64 to float32, are allowed.\n",
      " |   |            * 'unsafe' means any data conversions may be done.\n",
      " |   |      subok : bool, optional\n",
      " |   |          If True, then sub-classes will be passed-through (default), otherwise\n",
      " |   |          the returned array will be forced to be a base-class array.\n",
      " |   |      copy : bool, optional\n",
      " |   |          By default, astype always returns a newly allocated array. If this\n",
      " |   |          is set to false, and the `dtype`, `order`, and `subok`\n",
      " |   |          requirements are satisfied, the input array is returned instead\n",
      " |   |          of a copy.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      arr_t : ndarray\n",
      " |   |          Unless `copy` is False and the other conditions for returning the input\n",
      " |   |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      " |   |          is a new array of the same shape as the input array, with dtype, order\n",
      " |   |          given by `dtype`, `order`.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Starting in NumPy 1.9, astype method now returns an error if the string\n",
      " |   |      dtype to cast to is not long enough in 'safe' casting mode to hold the max\n",
      " |   |      value of integer/float array that is being casted. Previously the casting\n",
      " |   |      was allowed even if the result was truncated.\n",
      " |   |      \n",
      " |   |      Raises\n",
      " |   |      ------\n",
      " |   |      ComplexWarning\n",
      " |   |          When casting from complex to float or int. To avoid this,\n",
      " |   |          one should use ``a.real.astype(t)``.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([1, 2, 2.5])\n",
      " |   |      >>> x\n",
      " |   |      array([ 1. ,  2. ,  2.5])\n",
      " |   |      \n",
      " |   |      >>> x.astype(int)\n",
      " |   |      array([1, 2, 2])\n",
      " |   |  \n",
      " |   |  byteswap(...)\n",
      " |   |      a.byteswap(inplace=False)\n",
      " |   |      \n",
      " |   |      Swap the bytes of the array elements\n",
      " |   |      \n",
      " |   |      Toggle between low-endian and big-endian data representation by\n",
      " |   |      returning a byteswapped array, optionally swapped in-place.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      inplace : bool, optional\n",
      " |   |          If ``True``, swap bytes in-place, default is ``False``.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      out : ndarray\n",
      " |   |          The byteswapped array. If `inplace` is ``True``, this is\n",
      " |   |          a view to self.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      " |   |      >>> map(hex, A)\n",
      " |   |      ['0x1', '0x100', '0x2233']\n",
      " |   |      >>> A.byteswap(inplace=True)\n",
      " |   |      array([  256,     1, 13090], dtype=int16)\n",
      " |   |      >>> map(hex, A)\n",
      " |   |      ['0x100', '0x1', '0x3322']\n",
      " |   |      \n",
      " |   |      Arrays of strings are not swapped\n",
      " |   |      \n",
      " |   |      >>> A = np.array(['ceg', 'fac'])\n",
      " |   |      >>> A.byteswap()\n",
      " |   |      array(['ceg', 'fac'],\n",
      " |   |            dtype='|S3')\n",
      " |   |  \n",
      " |   |  choose(...)\n",
      " |   |      a.choose(choices, out=None, mode='raise')\n",
      " |   |      \n",
      " |   |      Use an index array to construct a new array from a set of choices.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.choose` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.choose : equivalent function\n",
      " |   |  \n",
      " |   |  clip(...)\n",
      " |   |      a.clip(min=None, max=None, out=None)\n",
      " |   |      \n",
      " |   |      Return an array whose values are limited to ``[min, max]``.\n",
      " |   |      One of max or min must be given.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.clip` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.clip : equivalent function\n",
      " |   |  \n",
      " |   |  compress(...)\n",
      " |   |      a.compress(condition, axis=None, out=None)\n",
      " |   |      \n",
      " |   |      Return selected slices of this array along given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.compress` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.compress : equivalent function\n",
      " |   |  \n",
      " |   |  conj(...)\n",
      " |   |      a.conj()\n",
      " |   |      \n",
      " |   |      Complex-conjugate all elements.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.conjugate` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.conjugate : equivalent function\n",
      " |   |  \n",
      " |   |  conjugate(...)\n",
      " |   |      a.conjugate()\n",
      " |   |      \n",
      " |   |      Return the complex conjugate, element-wise.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.conjugate` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.conjugate : equivalent function\n",
      " |   |  \n",
      " |   |  copy(...)\n",
      " |   |      a.copy(order='C')\n",
      " |   |      \n",
      " |   |      Return a copy of the array.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |   |          Controls the memory layout of the copy. 'C' means C-order,\n",
      " |   |          'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      " |   |          'C' otherwise. 'K' means match the layout of `a` as closely\n",
      " |   |          as possible. (Note that this function and :func:`numpy.copy` are very\n",
      " |   |          similar, but have different default values for their order=\n",
      " |   |          arguments.)\n",
      " |   |      \n",
      " |   |      See also\n",
      " |   |      --------\n",
      " |   |      numpy.copy\n",
      " |   |      numpy.copyto\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([[1,2,3],[4,5,6]], order='F')\n",
      " |   |      \n",
      " |   |      >>> y = x.copy()\n",
      " |   |      \n",
      " |   |      >>> x.fill(0)\n",
      " |   |      \n",
      " |   |      >>> x\n",
      " |   |      array([[0, 0, 0],\n",
      " |   |             [0, 0, 0]])\n",
      " |   |      \n",
      " |   |      >>> y\n",
      " |   |      array([[1, 2, 3],\n",
      " |   |             [4, 5, 6]])\n",
      " |   |      \n",
      " |   |      >>> y.flags['C_CONTIGUOUS']\n",
      " |   |      True\n",
      " |   |  \n",
      " |   |  cumprod(...)\n",
      " |   |      a.cumprod(axis=None, dtype=None, out=None)\n",
      " |   |      \n",
      " |   |      Return the cumulative product of the elements along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.cumprod` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.cumprod : equivalent function\n",
      " |   |  \n",
      " |   |  cumsum(...)\n",
      " |   |      a.cumsum(axis=None, dtype=None, out=None)\n",
      " |   |      \n",
      " |   |      Return the cumulative sum of the elements along the given axis.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.cumsum` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.cumsum : equivalent function\n",
      " |   |  \n",
      " |   |  diagonal(...)\n",
      " |   |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      " |   |      \n",
      " |   |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      " |   |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      " |   |      a future version the read-only restriction will be removed.\n",
      " |   |      \n",
      " |   |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.diagonal : equivalent function\n",
      " |   |  \n",
      " |   |  dot(...)\n",
      " |   |      a.dot(b, out=None)\n",
      " |   |      \n",
      " |   |      Dot product of two arrays.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.dot` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.dot : equivalent function\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> a = np.eye(2)\n",
      " |   |      >>> b = np.ones((2, 2)) * 2\n",
      " |   |      >>> a.dot(b)\n",
      " |   |      array([[ 2.,  2.],\n",
      " |   |             [ 2.,  2.]])\n",
      " |   |      \n",
      " |   |      This array method can be conveniently chained:\n",
      " |   |      \n",
      " |   |      >>> a.dot(b).dot(b)\n",
      " |   |      array([[ 8.,  8.],\n",
      " |   |             [ 8.,  8.]])\n",
      " |   |  \n",
      " |   |  dump(...)\n",
      " |   |      a.dump(file)\n",
      " |   |      \n",
      " |   |      Dump a pickle of the array to the specified file.\n",
      " |   |      The array can be read back with pickle.load or numpy.load.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      file : str\n",
      " |   |          A string naming the dump file.\n",
      " |   |  \n",
      " |   |  dumps(...)\n",
      " |   |      a.dumps()\n",
      " |   |      \n",
      " |   |      Returns the pickle of the array as a string.\n",
      " |   |      pickle.loads or numpy.loads will convert the string back to an array.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |  \n",
      " |   |  fill(...)\n",
      " |   |      a.fill(value)\n",
      " |   |      \n",
      " |   |      Fill the array with a scalar value.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      value : scalar\n",
      " |   |          All elements of `a` will be assigned this value.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> a = np.array([1, 2])\n",
      " |   |      >>> a.fill(0)\n",
      " |   |      >>> a\n",
      " |   |      array([0, 0])\n",
      " |   |      >>> a = np.empty(2)\n",
      " |   |      >>> a.fill(1)\n",
      " |   |      >>> a\n",
      " |   |      array([ 1.,  1.])\n",
      " |   |  \n",
      " |   |  getfield(...)\n",
      " |   |      a.getfield(dtype, offset=0)\n",
      " |   |      \n",
      " |   |      Returns a field of the given array as a certain type.\n",
      " |   |      \n",
      " |   |      A field is a view of the array data with a given data-type. The values in\n",
      " |   |      the view are determined by the given type and the offset into the current\n",
      " |   |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      " |   |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      " |   |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      " |   |      between 0 and 12 bytes.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      dtype : str or dtype\n",
      " |   |          The data type of the view. The dtype size of the view can not be larger\n",
      " |   |          than that of the array itself.\n",
      " |   |      offset : int\n",
      " |   |          Number of bytes to skip before beginning the element view.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.diag([1.+1.j]*2)\n",
      " |   |      >>> x[1, 1] = 2 + 4.j\n",
      " |   |      >>> x\n",
      " |   |      array([[ 1.+1.j,  0.+0.j],\n",
      " |   |             [ 0.+0.j,  2.+4.j]])\n",
      " |   |      >>> x.getfield(np.float64)\n",
      " |   |      array([[ 1.,  0.],\n",
      " |   |             [ 0.,  2.]])\n",
      " |   |      \n",
      " |   |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      " |   |      array for our view:\n",
      " |   |      \n",
      " |   |      >>> x.getfield(np.float64, offset=8)\n",
      " |   |      array([[ 1.,  0.],\n",
      " |   |         [ 0.,  4.]])\n",
      " |   |  \n",
      " |   |  item(...)\n",
      " |   |      a.item(*args)\n",
      " |   |      \n",
      " |   |      Copy an element of an array to a standard Python scalar and return it.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      \\*args : Arguments (variable number and type)\n",
      " |   |      \n",
      " |   |          * none: in this case, the method only works for arrays\n",
      " |   |            with one element (`a.size == 1`), which element is\n",
      " |   |            copied into a standard Python scalar object and returned.\n",
      " |   |      \n",
      " |   |          * int_type: this argument is interpreted as a flat index into\n",
      " |   |            the array, specifying which element to copy and return.\n",
      " |   |      \n",
      " |   |          * tuple of int_types: functions as does a single int_type argument,\n",
      " |   |            except that the argument is interpreted as an nd-index into the\n",
      " |   |            array.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      z : Standard Python scalar object\n",
      " |   |          A copy of the specified element of the array as a suitable\n",
      " |   |          Python scalar\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      When the data type of `a` is longdouble or clongdouble, item() returns\n",
      " |   |      a scalar array object because there is no available Python scalar that\n",
      " |   |      would not lose information. Void arrays return a buffer object for item(),\n",
      " |   |      unless fields are defined, in which case a tuple is returned.\n",
      " |   |      \n",
      " |   |      `item` is very similar to a[args], except, instead of an array scalar,\n",
      " |   |      a standard Python scalar is returned. This can be useful for speeding up\n",
      " |   |      access to elements of the array and doing arithmetic on elements of the\n",
      " |   |      array using Python's optimized math.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.random.randint(9, size=(3, 3))\n",
      " |   |      >>> x\n",
      " |   |      array([[3, 1, 7],\n",
      " |   |             [2, 8, 3],\n",
      " |   |             [8, 5, 3]])\n",
      " |   |      >>> x.item(3)\n",
      " |   |      2\n",
      " |   |      >>> x.item(7)\n",
      " |   |      5\n",
      " |   |      >>> x.item((0, 1))\n",
      " |   |      1\n",
      " |   |      >>> x.item((2, 2))\n",
      " |   |      3\n",
      " |   |  \n",
      " |   |  itemset(...)\n",
      " |   |      a.itemset(*args)\n",
      " |   |      \n",
      " |   |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      " |   |      \n",
      " |   |      There must be at least 1 argument, and define the last argument\n",
      " |   |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      " |   |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      " |   |      must select a single item in the array `a`.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      \\*args : Arguments\n",
      " |   |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      " |   |          If two arguments: the last argument is the value to be set\n",
      " |   |          and must be a scalar, the first argument specifies a single array\n",
      " |   |          element location. It is either an int or a tuple.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      " |   |      for placing a scalar into a particular location in an `ndarray`,\n",
      " |   |      if you must do this.  However, generally this is discouraged:\n",
      " |   |      among other problems, it complicates the appearance of the code.\n",
      " |   |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      " |   |      to assign the methods to a local variable to avoid the attribute\n",
      " |   |      look-up at each loop iteration.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.random.randint(9, size=(3, 3))\n",
      " |   |      >>> x\n",
      " |   |      array([[3, 1, 7],\n",
      " |   |             [2, 8, 3],\n",
      " |   |             [8, 5, 3]])\n",
      " |   |      >>> x.itemset(4, 0)\n",
      " |   |      >>> x.itemset((2, 2), 9)\n",
      " |   |      >>> x\n",
      " |   |      array([[3, 1, 7],\n",
      " |   |             [2, 0, 3],\n",
      " |   |             [8, 5, 9]])\n",
      " |   |  \n",
      " |   |  newbyteorder(...)\n",
      " |   |      arr.newbyteorder(new_order='S')\n",
      " |   |      \n",
      " |   |      Return the array with the same data viewed with a different byte order.\n",
      " |   |      \n",
      " |   |      Equivalent to::\n",
      " |   |      \n",
      " |   |          arr.view(arr.dtype.newbytorder(new_order))\n",
      " |   |      \n",
      " |   |      Changes are also made in all fields and sub-arrays of the array data\n",
      " |   |      type.\n",
      " |   |      \n",
      " |   |      \n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      new_order : string, optional\n",
      " |   |          Byte order to force; a value from the byte order specifications\n",
      " |   |          below. `new_order` codes can be any of:\n",
      " |   |      \n",
      " |   |          * 'S' - swap dtype from current to opposite endian\n",
      " |   |          * {'<', 'L'} - little endian\n",
      " |   |          * {'>', 'B'} - big endian\n",
      " |   |          * {'=', 'N'} - native order\n",
      " |   |          * {'|', 'I'} - ignore (no change to byte order)\n",
      " |   |      \n",
      " |   |          The default value ('S') results in swapping the current\n",
      " |   |          byte order. The code does a case-insensitive check on the first\n",
      " |   |          letter of `new_order` for the alternatives above.  For example,\n",
      " |   |          any of 'B' or 'b' or 'biggish' are valid to specify big-endian.\n",
      " |   |      \n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      new_arr : array\n",
      " |   |          New array object with the dtype reflecting given change to the\n",
      " |   |          byte order.\n",
      " |   |  \n",
      " |   |  nonzero(...)\n",
      " |   |      a.nonzero()\n",
      " |   |      \n",
      " |   |      Return the indices of the elements that are non-zero.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.nonzero` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.nonzero : equivalent function\n",
      " |   |  \n",
      " |   |  partition(...)\n",
      " |   |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      " |   |      \n",
      " |   |      Rearranges the elements in the array in such a way that value of the\n",
      " |   |      element in kth position is in the position it would be in a sorted array.\n",
      " |   |      All elements smaller than the kth element are moved before this element and\n",
      " |   |      all equal or greater are moved behind it. The ordering of the elements in\n",
      " |   |      the two partitions is undefined.\n",
      " |   |      \n",
      " |   |      .. versionadded:: 1.8.0\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      kth : int or sequence of ints\n",
      " |   |          Element index to partition by. The kth element value will be in its\n",
      " |   |          final sorted position and all smaller elements will be moved before it\n",
      " |   |          and all equal or greater elements behind it.\n",
      " |   |          The order all elements in the partitions is undefined.\n",
      " |   |          If provided with a sequence of kth it will partition all elements\n",
      " |   |          indexed by kth of them into their sorted position at once.\n",
      " |   |      axis : int, optional\n",
      " |   |          Axis along which to sort. Default is -1, which means sort along the\n",
      " |   |          last axis.\n",
      " |   |      kind : {'introselect'}, optional\n",
      " |   |          Selection algorithm. Default is 'introselect'.\n",
      " |   |      order : str or list of str, optional\n",
      " |   |          When `a` is an array with fields defined, this argument specifies\n",
      " |   |          which fields to compare first, second, etc.  A single field can\n",
      " |   |          be specified as a string, and not all fields need be specified,\n",
      " |   |          but unspecified fields will still be used, in the order in which\n",
      " |   |          they come up in the dtype, to break ties.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.partition : Return a parititioned copy of an array.\n",
      " |   |      argpartition : Indirect partition.\n",
      " |   |      sort : Full sort.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      See ``np.partition`` for notes on the different algorithms.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> a = np.array([3, 4, 2, 1])\n",
      " |   |      >>> a.partition(3)\n",
      " |   |      >>> a\n",
      " |   |      array([2, 1, 3, 4])\n",
      " |   |      \n",
      " |   |      >>> a.partition((1, 3))\n",
      " |   |      array([1, 2, 3, 4])\n",
      " |   |  \n",
      " |   |  put(...)\n",
      " |   |      a.put(indices, values, mode='raise')\n",
      " |   |      \n",
      " |   |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.put` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.put : equivalent function\n",
      " |   |  \n",
      " |   |  repeat(...)\n",
      " |   |      a.repeat(repeats, axis=None)\n",
      " |   |      \n",
      " |   |      Repeat elements of an array.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.repeat` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.repeat : equivalent function\n",
      " |   |  \n",
      " |   |  reshape(...)\n",
      " |   |      a.reshape(shape, order='C')\n",
      " |   |      \n",
      " |   |      Returns an array containing the same data with a new shape.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.reshape` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.reshape : equivalent function\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      " |   |      the elements of the shape parameter to be passed in as separate arguments.\n",
      " |   |      For example, ``a.reshape(10, 11)`` is equivalent to\n",
      " |   |      ``a.reshape((10, 11))``.\n",
      " |   |  \n",
      " |   |  resize(...)\n",
      " |   |      a.resize(new_shape, refcheck=True)\n",
      " |   |      \n",
      " |   |      Change shape and size of array in-place.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      new_shape : tuple of ints, or `n` ints\n",
      " |   |          Shape of resized array.\n",
      " |   |      refcheck : bool, optional\n",
      " |   |          If False, reference count will not be checked. Default is True.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Raises\n",
      " |   |      ------\n",
      " |   |      ValueError\n",
      " |   |          If `a` does not own its own data or references or views to it exist,\n",
      " |   |          and the data memory must be changed.\n",
      " |   |          PyPy only: will always raise if the data memory must be changed, since\n",
      " |   |          there is no reliable way to determine if references or views to it\n",
      " |   |          exist.\n",
      " |   |      \n",
      " |   |      SystemError\n",
      " |   |          If the `order` keyword argument is specified. This behaviour is a\n",
      " |   |          bug in NumPy.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      resize : Return a new array with the specified shape.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This reallocates space for the data area if necessary.\n",
      " |   |      \n",
      " |   |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      " |   |      resized.\n",
      " |   |      \n",
      " |   |      The purpose of the reference count check is to make sure you\n",
      " |   |      do not use this array as a buffer for another Python object and then\n",
      " |   |      reallocate the memory. However, reference counts can increase in\n",
      " |   |      other ways so if you are sure that you have not shared the memory\n",
      " |   |      for this array with another Python object, then you may safely set\n",
      " |   |      `refcheck` to False.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      Shrinking an array: array is flattened (in the order that the data are\n",
      " |   |      stored in memory), resized, and reshaped:\n",
      " |   |      \n",
      " |   |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      " |   |      >>> a.resize((2, 1))\n",
      " |   |      >>> a\n",
      " |   |      array([[0],\n",
      " |   |             [1]])\n",
      " |   |      \n",
      " |   |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      " |   |      >>> a.resize((2, 1))\n",
      " |   |      >>> a\n",
      " |   |      array([[0],\n",
      " |   |             [2]])\n",
      " |   |      \n",
      " |   |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      " |   |      \n",
      " |   |      >>> b = np.array([[0, 1], [2, 3]])\n",
      " |   |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      " |   |      >>> b\n",
      " |   |      array([[0, 1, 2],\n",
      " |   |             [3, 0, 0]])\n",
      " |   |      \n",
      " |   |      Referencing an array prevents resizing...\n",
      " |   |      \n",
      " |   |      >>> c = a\n",
      " |   |      >>> a.resize((1, 1))\n",
      " |   |      Traceback (most recent call last):\n",
      " |   |      ...\n",
      " |   |      ValueError: cannot resize an array that has been referenced ...\n",
      " |   |      \n",
      " |   |      Unless `refcheck` is False:\n",
      " |   |      \n",
      " |   |      >>> a.resize((1, 1), refcheck=False)\n",
      " |   |      >>> a\n",
      " |   |      array([[0]])\n",
      " |   |      >>> c\n",
      " |   |      array([[0]])\n",
      " |   |  \n",
      " |   |  round(...)\n",
      " |   |      a.round(decimals=0, out=None)\n",
      " |   |      \n",
      " |   |      Return `a` with each element rounded to the given number of decimals.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.around` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.around : equivalent function\n",
      " |   |  \n",
      " |   |  searchsorted(...)\n",
      " |   |      a.searchsorted(v, side='left', sorter=None)\n",
      " |   |      \n",
      " |   |      Find indices where elements of v should be inserted in a to maintain order.\n",
      " |   |      \n",
      " |   |      For full documentation, see `numpy.searchsorted`\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.searchsorted : equivalent function\n",
      " |   |  \n",
      " |   |  setfield(...)\n",
      " |   |      a.setfield(val, dtype, offset=0)\n",
      " |   |      \n",
      " |   |      Put a value into a specified place in a field defined by a data-type.\n",
      " |   |      \n",
      " |   |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      " |   |      bytes into the field.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      val : object\n",
      " |   |          Value to be placed in field.\n",
      " |   |      dtype : dtype object\n",
      " |   |          Data-type of the field in which to place `val`.\n",
      " |   |      offset : int, optional\n",
      " |   |          The number of bytes into the field at which to place `val`.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      getfield\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.eye(3)\n",
      " |   |      >>> x.getfield(np.float64)\n",
      " |   |      array([[ 1.,  0.,  0.],\n",
      " |   |             [ 0.,  1.,  0.],\n",
      " |   |             [ 0.,  0.,  1.]])\n",
      " |   |      >>> x.setfield(3, np.int32)\n",
      " |   |      >>> x.getfield(np.int32)\n",
      " |   |      array([[3, 3, 3],\n",
      " |   |             [3, 3, 3],\n",
      " |   |             [3, 3, 3]])\n",
      " |   |      >>> x\n",
      " |   |      array([[  1.00000000e+000,   1.48219694e-323,   1.48219694e-323],\n",
      " |   |             [  1.48219694e-323,   1.00000000e+000,   1.48219694e-323],\n",
      " |   |             [  1.48219694e-323,   1.48219694e-323,   1.00000000e+000]])\n",
      " |   |      >>> x.setfield(np.eye(3), np.int32)\n",
      " |   |      >>> x\n",
      " |   |      array([[ 1.,  0.,  0.],\n",
      " |   |             [ 0.,  1.,  0.],\n",
      " |   |             [ 0.,  0.,  1.]])\n",
      " |   |  \n",
      " |   |  setflags(...)\n",
      " |   |      a.setflags(write=None, align=None, uic=None)\n",
      " |   |      \n",
      " |   |      Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\n",
      " |   |      respectively.\n",
      " |   |      \n",
      " |   |      These Boolean-valued flags affect how numpy interprets the memory\n",
      " |   |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      " |   |      be set to True if the data is actually aligned according to the type.\n",
      " |   |      The WRITEBACKIFCOPY and (deprecated) UPDATEIFCOPY flags can never be set\n",
      " |   |      to True. The flag WRITEABLE can only be set to True if the array owns its\n",
      " |   |      own memory, or the ultimate owner of the memory exposes a writeable buffer\n",
      " |   |      interface, or is a string. (The exception for string is made so that\n",
      " |   |      unpickling can be done without copying memory.)\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      write : bool, optional\n",
      " |   |          Describes whether or not `a` can be written to.\n",
      " |   |      align : bool, optional\n",
      " |   |          Describes whether or not `a` is aligned properly for its type.\n",
      " |   |      uic : bool, optional\n",
      " |   |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Array flags provide information about how the memory area used\n",
      " |   |      for the array is to be interpreted. There are 7 Boolean flags\n",
      " |   |      in use, only four of which can be changed by the user:\n",
      " |   |      WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n",
      " |   |      \n",
      " |   |      WRITEABLE (W) the data area can be written to;\n",
      " |   |      \n",
      " |   |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      " |   |      (as determined by the compiler);\n",
      " |   |      \n",
      " |   |      UPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n",
      " |   |      \n",
      " |   |      WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced\n",
      " |   |      by .base). When the C-API function PyArray_ResolveWritebackIfCopy is\n",
      " |   |      called, the base array will be updated with the contents of this array.\n",
      " |   |      \n",
      " |   |      All flags can be accessed using the single (upper case) letter as well\n",
      " |   |      as the full name.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> y\n",
      " |   |      array([[3, 1, 7],\n",
      " |   |             [2, 0, 0],\n",
      " |   |             [8, 5, 9]])\n",
      " |   |      >>> y.flags\n",
      " |   |        C_CONTIGUOUS : True\n",
      " |   |        F_CONTIGUOUS : False\n",
      " |   |        OWNDATA : True\n",
      " |   |        WRITEABLE : True\n",
      " |   |        ALIGNED : True\n",
      " |   |        WRITEBACKIFCOPY : False\n",
      " |   |        UPDATEIFCOPY : False\n",
      " |   |      >>> y.setflags(write=0, align=0)\n",
      " |   |      >>> y.flags\n",
      " |   |        C_CONTIGUOUS : True\n",
      " |   |        F_CONTIGUOUS : False\n",
      " |   |        OWNDATA : True\n",
      " |   |        WRITEABLE : False\n",
      " |   |        ALIGNED : False\n",
      " |   |        WRITEBACKIFCOPY : False\n",
      " |   |        UPDATEIFCOPY : False\n",
      " |   |      >>> y.setflags(uic=1)\n",
      " |   |      Traceback (most recent call last):\n",
      " |   |        File \"<stdin>\", line 1, in <module>\n",
      " |   |      ValueError: cannot set WRITEBACKIFCOPY flag to True\n",
      " |   |  \n",
      " |   |  sort(...)\n",
      " |   |      a.sort(axis=-1, kind='quicksort', order=None)\n",
      " |   |      \n",
      " |   |      Sort an array, in-place.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      axis : int, optional\n",
      " |   |          Axis along which to sort. Default is -1, which means sort along the\n",
      " |   |          last axis.\n",
      " |   |      kind : {'quicksort', 'mergesort', 'heapsort'}, optional\n",
      " |   |          Sorting algorithm. Default is 'quicksort'.\n",
      " |   |      order : str or list of str, optional\n",
      " |   |          When `a` is an array with fields defined, this argument specifies\n",
      " |   |          which fields to compare first, second, etc.  A single field can\n",
      " |   |          be specified as a string, and not all fields need be specified,\n",
      " |   |          but unspecified fields will still be used, in the order in which\n",
      " |   |          they come up in the dtype, to break ties.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.sort : Return a sorted copy of an array.\n",
      " |   |      argsort : Indirect sort.\n",
      " |   |      lexsort : Indirect stable sort on multiple keys.\n",
      " |   |      searchsorted : Find elements in sorted array.\n",
      " |   |      partition: Partial sort.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      See ``sort`` for notes on the different sorting algorithms.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> a = np.array([[1,4], [3,1]])\n",
      " |   |      >>> a.sort(axis=1)\n",
      " |   |      >>> a\n",
      " |   |      array([[1, 4],\n",
      " |   |             [1, 3]])\n",
      " |   |      >>> a.sort(axis=0)\n",
      " |   |      >>> a\n",
      " |   |      array([[1, 3],\n",
      " |   |             [1, 4]])\n",
      " |   |      \n",
      " |   |      Use the `order` keyword to specify a field to use when sorting a\n",
      " |   |      structured array:\n",
      " |   |      \n",
      " |   |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      " |   |      >>> a.sort(order='y')\n",
      " |   |      >>> a\n",
      " |   |      array([('c', 1), ('a', 2)],\n",
      " |   |            dtype=[('x', '|S1'), ('y', '<i4')])\n",
      " |   |  \n",
      " |   |  swapaxes(...)\n",
      " |   |      a.swapaxes(axis1, axis2)\n",
      " |   |      \n",
      " |   |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.swapaxes` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.swapaxes : equivalent function\n",
      " |   |  \n",
      " |   |  take(...)\n",
      " |   |      a.take(indices, axis=None, out=None, mode='raise')\n",
      " |   |      \n",
      " |   |      Return an array formed from the elements of `a` at the given indices.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.take` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.take : equivalent function\n",
      " |   |  \n",
      " |   |  tobytes(...)\n",
      " |   |      a.tobytes(order='C')\n",
      " |   |      \n",
      " |   |      Construct Python bytes containing the raw data bytes in the array.\n",
      " |   |      \n",
      " |   |      Constructs Python bytes showing a copy of the raw contents of\n",
      " |   |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      " |   |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      " |   |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      " |   |      means 'Fortran' order.\n",
      " |   |      \n",
      " |   |      .. versionadded:: 1.9.0\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      order : {'C', 'F', None}, optional\n",
      " |   |          Order of the data for multidimensional arrays:\n",
      " |   |          C, Fortran, or the same as for the original array.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      s : bytes\n",
      " |   |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([[0, 1], [2, 3]])\n",
      " |   |      >>> x.tobytes()\n",
      " |   |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      " |   |      >>> x.tobytes('C') == x.tobytes()\n",
      " |   |      True\n",
      " |   |      >>> x.tobytes('F')\n",
      " |   |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      " |   |  \n",
      " |   |  tofile(...)\n",
      " |   |      a.tofile(fid, sep=\"\", format=\"%s\")\n",
      " |   |      \n",
      " |   |      Write array to a file as text or binary (default).\n",
      " |   |      \n",
      " |   |      Data is always written in 'C' order, independent of the order of `a`.\n",
      " |   |      The data produced by this method can be recovered using the function\n",
      " |   |      fromfile().\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      fid : file or str\n",
      " |   |          An open file object, or a string containing a filename.\n",
      " |   |      sep : str\n",
      " |   |          Separator between array items for text output.\n",
      " |   |          If \"\" (empty), a binary file is written, equivalent to\n",
      " |   |          ``file.write(a.tobytes())``.\n",
      " |   |      format : str\n",
      " |   |          Format string for text file output.\n",
      " |   |          Each entry in the array is formatted to text by first converting\n",
      " |   |          it to the closest Python type, and then using \"format\" % item.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      This is a convenience function for quick storage of array data.\n",
      " |   |      Information on endianness and precision is lost, so this method is not a\n",
      " |   |      good choice for files intended to archive data or transport data between\n",
      " |   |      machines with different endianness. Some of these problems can be overcome\n",
      " |   |      by outputting the data as text files, at the expense of speed and file\n",
      " |   |      size.\n",
      " |   |  \n",
      " |   |  tostring(...)\n",
      " |   |      a.tostring(order='C')\n",
      " |   |      \n",
      " |   |      Construct Python bytes containing the raw data bytes in the array.\n",
      " |   |      \n",
      " |   |      Constructs Python bytes showing a copy of the raw contents of\n",
      " |   |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      " |   |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      " |   |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      " |   |      means 'Fortran' order.\n",
      " |   |      \n",
      " |   |      This function is a compatibility alias for tobytes. Despite its name it returns bytes not strings.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      order : {'C', 'F', None}, optional\n",
      " |   |          Order of the data for multidimensional arrays:\n",
      " |   |          C, Fortran, or the same as for the original array.\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      s : bytes\n",
      " |   |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([[0, 1], [2, 3]])\n",
      " |   |      >>> x.tobytes()\n",
      " |   |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      " |   |      >>> x.tobytes('C') == x.tobytes()\n",
      " |   |      True\n",
      " |   |      >>> x.tobytes('F')\n",
      " |   |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      " |   |  \n",
      " |   |  trace(...)\n",
      " |   |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      " |   |      \n",
      " |   |      Return the sum along diagonals of the array.\n",
      " |   |      \n",
      " |   |      Refer to `numpy.trace` for full documentation.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.trace : equivalent function\n",
      " |   |  \n",
      " |   |  transpose(...)\n",
      " |   |      a.transpose(*axes)\n",
      " |   |      \n",
      " |   |      Returns a view of the array with axes transposed.\n",
      " |   |      \n",
      " |   |      For a 1-D array, this has no effect. (To change between column and\n",
      " |   |      row vectors, first cast the 1-D array into a matrix object.)\n",
      " |   |      For a 2-D array, this is the usual matrix transpose.\n",
      " |   |      For an n-D array, if axes are given, their order indicates how the\n",
      " |   |      axes are permuted (see Examples). If axes are not provided and\n",
      " |   |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      " |   |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      axes : None, tuple of ints, or `n` ints\n",
      " |   |      \n",
      " |   |       * None or no argument: reverses the order of the axes.\n",
      " |   |      \n",
      " |   |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      " |   |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      " |   |      \n",
      " |   |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      " |   |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      out : ndarray\n",
      " |   |          View of `a`, with axes suitably permuted.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      ndarray.T : Array property returning the array transposed.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> a = np.array([[1, 2], [3, 4]])\n",
      " |   |      >>> a\n",
      " |   |      array([[1, 2],\n",
      " |   |             [3, 4]])\n",
      " |   |      >>> a.transpose()\n",
      " |   |      array([[1, 3],\n",
      " |   |             [2, 4]])\n",
      " |   |      >>> a.transpose((1, 0))\n",
      " |   |      array([[1, 3],\n",
      " |   |             [2, 4]])\n",
      " |   |      >>> a.transpose(1, 0)\n",
      " |   |      array([[1, 3],\n",
      " |   |             [2, 4]])\n",
      " |   |  \n",
      " |   |  view(...)\n",
      " |   |      a.view(dtype=None, type=None)\n",
      " |   |      \n",
      " |   |      New view of array with the same data.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      dtype : data-type or ndarray sub-class, optional\n",
      " |   |          Data-type descriptor of the returned view, e.g., float32 or int16. The\n",
      " |   |          default, None, results in the view having the same data-type as `a`.\n",
      " |   |          This argument can also be specified as an ndarray sub-class, which\n",
      " |   |          then specifies the type of the returned object (this is equivalent to\n",
      " |   |          setting the ``type`` parameter).\n",
      " |   |      type : Python type, optional\n",
      " |   |          Type of the returned view, e.g., ndarray or matrix.  Again, the\n",
      " |   |          default None results in type preservation.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      ``a.view()`` is used two different ways:\n",
      " |   |      \n",
      " |   |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      " |   |      of the array's memory with a different data-type.  This can cause a\n",
      " |   |      reinterpretation of the bytes of memory.\n",
      " |   |      \n",
      " |   |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      " |   |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      " |   |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      " |   |      memory.\n",
      " |   |      \n",
      " |   |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      " |   |      bytes per entry than the previous dtype (for example, converting a\n",
      " |   |      regular array to a structured array), then the behavior of the view\n",
      " |   |      cannot be predicted just from the superficial appearance of ``a`` (shown\n",
      " |   |      by ``print(a)``). It also depends on exactly how ``a`` is stored in\n",
      " |   |      memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus\n",
      " |   |      defined as a slice or transpose, etc., the view may give different\n",
      " |   |      results.\n",
      " |   |      \n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      " |   |      \n",
      " |   |      Viewing array data using a different type and dtype:\n",
      " |   |      \n",
      " |   |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      " |   |      >>> y\n",
      " |   |      matrix([[513]], dtype=int16)\n",
      " |   |      >>> print(type(y))\n",
      " |   |      <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      " |   |      \n",
      " |   |      Creating a view on a structured array so it can be used in calculations\n",
      " |   |      \n",
      " |   |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      " |   |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      " |   |      >>> xv\n",
      " |   |      array([[1, 2],\n",
      " |   |             [3, 4]], dtype=int8)\n",
      " |   |      >>> xv.mean(0)\n",
      " |   |      array([ 2.,  3.])\n",
      " |   |      \n",
      " |   |      Making changes to the view changes the underlying array\n",
      " |   |      \n",
      " |   |      >>> xv[0,1] = 20\n",
      " |   |      >>> print(x)\n",
      " |   |      [(1, 20) (3, 4)]\n",
      " |   |      \n",
      " |   |      Using a view to convert an array to a recarray:\n",
      " |   |      \n",
      " |   |      >>> z = x.view(np.recarray)\n",
      " |   |      >>> z.a\n",
      " |   |      array([1], dtype=int8)\n",
      " |   |      \n",
      " |   |      Views share data:\n",
      " |   |      \n",
      " |   |      >>> x[0] = (9, 10)\n",
      " |   |      >>> z[0]\n",
      " |   |      (9, 10)\n",
      " |   |      \n",
      " |   |      Views that change the dtype size (bytes per entry) should normally be\n",
      " |   |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      " |   |      \n",
      " |   |      >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)\n",
      " |   |      >>> y = x[:, 0:2]\n",
      " |   |      >>> y\n",
      " |   |      array([[1, 2],\n",
      " |   |             [4, 5]], dtype=int16)\n",
      " |   |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      " |   |      Traceback (most recent call last):\n",
      " |   |        File \"<stdin>\", line 1, in <module>\n",
      " |   |      ValueError: new type not compatible with array.\n",
      " |   |      >>> z = y.copy()\n",
      " |   |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      " |   |      array([[(1, 2)],\n",
      " |   |             [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Data descriptors inherited from numpy.ndarray:\n",
      " |   |  \n",
      " |   |  __array_interface__\n",
      " |   |      Array protocol: Python side.\n",
      " |   |  \n",
      " |   |  __array_struct__\n",
      " |   |      Array protocol: C-struct side.\n",
      " |   |  \n",
      " |   |  base\n",
      " |   |      Base object if memory is from some other object.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      The base of an array that owns its memory is None:\n",
      " |   |      \n",
      " |   |      >>> x = np.array([1,2,3,4])\n",
      " |   |      >>> x.base is None\n",
      " |   |      True\n",
      " |   |      \n",
      " |   |      Slicing creates a view, whose memory is shared with x:\n",
      " |   |      \n",
      " |   |      >>> y = x[2:]\n",
      " |   |      >>> y.base is x\n",
      " |   |      True\n",
      " |   |  \n",
      " |   |  ctypes\n",
      " |   |      An object to simplify the interaction of the array with the ctypes\n",
      " |   |      module.\n",
      " |   |      \n",
      " |   |      This attribute creates an object that makes it easier to use arrays\n",
      " |   |      when calling shared libraries with the ctypes module. The returned\n",
      " |   |      object has, among others, data, shape, and strides attributes (see\n",
      " |   |      Notes below) which themselves return ctypes objects that can be used\n",
      " |   |      as arguments to a shared library.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      c : Python object\n",
      " |   |          Possessing attributes data, shape, strides, etc.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.ctypeslib\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Below are the public attributes of this object which were documented\n",
      " |   |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      " |   |      as well as documented private attributes):\n",
      " |   |      \n",
      " |   |      * data: A pointer to the memory area of the array as a Python integer.\n",
      " |   |        This memory area may contain data that is not aligned, or not in correct\n",
      " |   |        byte-order. The memory area may not even be writeable. The array\n",
      " |   |        flags and data-type of this array should be respected when passing this\n",
      " |   |        attribute to arbitrary C-code to avoid trouble that can include Python\n",
      " |   |        crashing. User Beware! The value of this attribute is exactly the same\n",
      " |   |        as self._array_interface_['data'][0].\n",
      " |   |      \n",
      " |   |      * shape (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      " |   |        the basetype is the C-integer corresponding to dtype('p') on this\n",
      " |   |        platform. This base-type could be c_int, c_long, or c_longlong\n",
      " |   |        depending on the platform. The c_intp type is defined accordingly in\n",
      " |   |        numpy.ctypeslib. The ctypes array contains the shape of the underlying\n",
      " |   |        array.\n",
      " |   |      \n",
      " |   |      * strides (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      " |   |        the basetype is the same as for the shape attribute. This ctypes array\n",
      " |   |        contains the strides information from the underlying array. This strides\n",
      " |   |        information is important for showing how many bytes must be jumped to\n",
      " |   |        get to the next element in the array.\n",
      " |   |      \n",
      " |   |      * data_as(obj): Return the data pointer cast to a particular c-types object.\n",
      " |   |        For example, calling self._as_parameter_ is equivalent to\n",
      " |   |        self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a\n",
      " |   |        pointer to a ctypes array of floating-point data:\n",
      " |   |        self.data_as(ctypes.POINTER(ctypes.c_double)).\n",
      " |   |      \n",
      " |   |      * shape_as(obj): Return the shape tuple as an array of some other c-types\n",
      " |   |        type. For example: self.shape_as(ctypes.c_short).\n",
      " |   |      \n",
      " |   |      * strides_as(obj): Return the strides tuple as an array of some other\n",
      " |   |        c-types type. For example: self.strides_as(ctypes.c_longlong).\n",
      " |   |      \n",
      " |   |      Be careful using the ctypes attribute - especially on temporary\n",
      " |   |      arrays or arrays constructed on the fly. For example, calling\n",
      " |   |      ``(a+b).ctypes.data_as(ctypes.c_void_p)`` returns a pointer to memory\n",
      " |   |      that is invalid because the array created as (a+b) is deallocated\n",
      " |   |      before the next Python statement. You can avoid this problem using\n",
      " |   |      either ``c=a+b`` or ``ct=(a+b).ctypes``. In the latter case, ct will\n",
      " |   |      hold a reference to the array until ct is deleted or re-assigned.\n",
      " |   |      \n",
      " |   |      If the ctypes module is not available, then the ctypes attribute\n",
      " |   |      of array objects still returns something useful, but ctypes objects\n",
      " |   |      are not returned and errors may be raised instead. In particular,\n",
      " |   |      the object will still have the as parameter attribute which will\n",
      " |   |      return an integer equal to the data attribute.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> import ctypes\n",
      " |   |      >>> x\n",
      " |   |      array([[0, 1],\n",
      " |   |             [2, 3]])\n",
      " |   |      >>> x.ctypes.data\n",
      " |   |      30439712\n",
      " |   |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long))\n",
      " |   |      <ctypes.LP_c_long object at 0x01F01300>\n",
      " |   |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long)).contents\n",
      " |   |      c_long(0)\n",
      " |   |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_longlong)).contents\n",
      " |   |      c_longlong(4294967296L)\n",
      " |   |      >>> x.ctypes.shape\n",
      " |   |      <numpy.core._internal.c_long_Array_2 object at 0x01FFD580>\n",
      " |   |      >>> x.ctypes.shape_as(ctypes.c_long)\n",
      " |   |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      " |   |      >>> x.ctypes.strides\n",
      " |   |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      " |   |      >>> x.ctypes.strides_as(ctypes.c_longlong)\n",
      " |   |      <numpy.core._internal.c_longlong_Array_2 object at 0x01F01300>\n",
      " |   |  \n",
      " |   |  data\n",
      " |   |      Python buffer object pointing to the start of the array's data.\n",
      " |   |  \n",
      " |   |  dtype\n",
      " |   |      Data-type of the array's elements.\n",
      " |   |      \n",
      " |   |      Parameters\n",
      " |   |      ----------\n",
      " |   |      None\n",
      " |   |      \n",
      " |   |      Returns\n",
      " |   |      -------\n",
      " |   |      d : numpy dtype object\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.dtype\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x\n",
      " |   |      array([[0, 1],\n",
      " |   |             [2, 3]])\n",
      " |   |      >>> x.dtype\n",
      " |   |      dtype('int32')\n",
      " |   |      >>> type(x.dtype)\n",
      " |   |      <type 'numpy.dtype'>\n",
      " |   |  \n",
      " |   |  flags\n",
      " |   |      Information about the memory layout of the array.\n",
      " |   |      \n",
      " |   |      Attributes\n",
      " |   |      ----------\n",
      " |   |      C_CONTIGUOUS (C)\n",
      " |   |          The data is in a single, C-style contiguous segment.\n",
      " |   |      F_CONTIGUOUS (F)\n",
      " |   |          The data is in a single, Fortran-style contiguous segment.\n",
      " |   |      OWNDATA (O)\n",
      " |   |          The array owns the memory it uses or borrows it from another object.\n",
      " |   |      WRITEABLE (W)\n",
      " |   |          The data area can be written to.  Setting this to False locks\n",
      " |   |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      " |   |          from its base array at creation time, but a view of a writeable\n",
      " |   |          array may be subsequently locked while the base array remains writeable.\n",
      " |   |          (The opposite is not true, in that a view of a locked array may not\n",
      " |   |          be made writeable.  However, currently, locking a base object does not\n",
      " |   |          lock any views that already reference it, so under that circumstance it\n",
      " |   |          is possible to alter the contents of a locked array via a previously\n",
      " |   |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      " |   |          array raises a RuntimeError exception.\n",
      " |   |      ALIGNED (A)\n",
      " |   |          The data and all elements are aligned appropriately for the hardware.\n",
      " |   |      WRITEBACKIFCOPY (X)\n",
      " |   |          This array is a copy of some other array. The C-API function\n",
      " |   |          PyArray_ResolveWritebackIfCopy must be called before deallocating\n",
      " |   |          to the base array will be updated with the contents of this array.\n",
      " |   |      UPDATEIFCOPY (U)\n",
      " |   |          (Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\n",
      " |   |          When this array is\n",
      " |   |          deallocated, the base array will be updated with the contents of\n",
      " |   |          this array.\n",
      " |   |      FNC\n",
      " |   |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      " |   |      FORC\n",
      " |   |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      " |   |      BEHAVED (B)\n",
      " |   |          ALIGNED and WRITEABLE.\n",
      " |   |      CARRAY (CA)\n",
      " |   |          BEHAVED and C_CONTIGUOUS.\n",
      " |   |      FARRAY (FA)\n",
      " |   |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      " |   |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      " |   |      names are only supported in dictionary access.\n",
      " |   |      \n",
      " |   |      Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\n",
      " |   |      changed by the user, via direct assignment to the attribute or dictionary\n",
      " |   |      entry, or by calling `ndarray.setflags`.\n",
      " |   |      \n",
      " |   |      The array flags cannot be set arbitrarily:\n",
      " |   |      \n",
      " |   |      - UPDATEIFCOPY can only be set ``False``.\n",
      " |   |      - WRITEBACKIFCOPY can only be set ``False``.\n",
      " |   |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      " |   |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      " |   |        or the ultimate owner of the memory exposes a writeable buffer\n",
      " |   |        interface or is a string.\n",
      " |   |      \n",
      " |   |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      " |   |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      " |   |      dimensional arrays.\n",
      " |   |      \n",
      " |   |      Even for contiguous arrays a stride for a given dimension\n",
      " |   |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      " |   |      or the array has no elements.\n",
      " |   |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      " |   |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      " |   |      Fortran-style contiguous arrays is true.\n",
      " |   |  \n",
      " |   |  flat\n",
      " |   |      A 1-D iterator over the array.\n",
      " |   |      \n",
      " |   |      This is a `numpy.flatiter` instance, which acts similarly to, but is not\n",
      " |   |      a subclass of, Python's built-in iterator object.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      flatten : Return a copy of the array collapsed into one dimension.\n",
      " |   |      \n",
      " |   |      flatiter\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.arange(1, 7).reshape(2, 3)\n",
      " |   |      >>> x\n",
      " |   |      array([[1, 2, 3],\n",
      " |   |             [4, 5, 6]])\n",
      " |   |      >>> x.flat[3]\n",
      " |   |      4\n",
      " |   |      >>> x.T\n",
      " |   |      array([[1, 4],\n",
      " |   |             [2, 5],\n",
      " |   |             [3, 6]])\n",
      " |   |      >>> x.T.flat[3]\n",
      " |   |      5\n",
      " |   |      >>> type(x.flat)\n",
      " |   |      <type 'numpy.flatiter'>\n",
      " |   |      \n",
      " |   |      An assignment example:\n",
      " |   |      \n",
      " |   |      >>> x.flat = 3; x\n",
      " |   |      array([[3, 3, 3],\n",
      " |   |             [3, 3, 3]])\n",
      " |   |      >>> x.flat[[1,4]] = 1; x\n",
      " |   |      array([[3, 1, 3],\n",
      " |   |             [3, 1, 3]])\n",
      " |   |  \n",
      " |   |  imag\n",
      " |   |      The imaginary part of the array.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      " |   |      >>> x.imag\n",
      " |   |      array([ 0.        ,  0.70710678])\n",
      " |   |      >>> x.imag.dtype\n",
      " |   |      dtype('float64')\n",
      " |   |  \n",
      " |   |  itemsize\n",
      " |   |      Length of one array element in bytes.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      " |   |      >>> x.itemsize\n",
      " |   |      8\n",
      " |   |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      " |   |      >>> x.itemsize\n",
      " |   |      16\n",
      " |   |  \n",
      " |   |  nbytes\n",
      " |   |      Total bytes consumed by the elements of the array.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Does not include memory consumed by non-element attributes of the\n",
      " |   |      array object.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      " |   |      >>> x.nbytes\n",
      " |   |      480\n",
      " |   |      >>> np.prod(x.shape) * x.itemsize\n",
      " |   |      480\n",
      " |   |  \n",
      " |   |  ndim\n",
      " |   |      Number of array dimensions.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([1, 2, 3])\n",
      " |   |      >>> x.ndim\n",
      " |   |      1\n",
      " |   |      >>> y = np.zeros((2, 3, 4))\n",
      " |   |      >>> y.ndim\n",
      " |   |      3\n",
      " |   |  \n",
      " |   |  real\n",
      " |   |      The real part of the array.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      " |   |      >>> x.real\n",
      " |   |      array([ 1.        ,  0.70710678])\n",
      " |   |      >>> x.real.dtype\n",
      " |   |      dtype('float64')\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.real : equivalent function\n",
      " |   |  \n",
      " |   |  shape\n",
      " |   |      Tuple of array dimensions.\n",
      " |   |      \n",
      " |   |      The shape property is usually used to get the current shape of an array,\n",
      " |   |      but may also be used to reshape the array in-place by assigning a tuple of\n",
      " |   |      array dimensions to it.  As with `numpy.reshape`, one of the new shape\n",
      " |   |      dimensions can be -1, in which case its value is inferred from the size of\n",
      " |   |      the array and the remaining dimensions. Reshaping an array in-place will\n",
      " |   |      fail if a copy is required.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.array([1, 2, 3, 4])\n",
      " |   |      >>> x.shape\n",
      " |   |      (4,)\n",
      " |   |      >>> y = np.zeros((2, 3, 4))\n",
      " |   |      >>> y.shape\n",
      " |   |      (2, 3, 4)\n",
      " |   |      >>> y.shape = (3, 8)\n",
      " |   |      >>> y\n",
      " |   |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      " |   |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      " |   |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      " |   |      >>> y.shape = (3, 6)\n",
      " |   |      Traceback (most recent call last):\n",
      " |   |        File \"<stdin>\", line 1, in <module>\n",
      " |   |      ValueError: total size of new array must be unchanged\n",
      " |   |      >>> np.zeros((4,2))[::2].shape = (-1,)\n",
      " |   |      Traceback (most recent call last):\n",
      " |   |        File \"<stdin>\", line 1, in <module>\n",
      " |   |      AttributeError: incompatible shape for a non-contiguous array\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.reshape : similar function\n",
      " |   |      ndarray.reshape : similar method\n",
      " |   |  \n",
      " |   |  size\n",
      " |   |      Number of elements in the array.\n",
      " |   |      \n",
      " |   |      Equivalent to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      " |   |      dimensions.\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      " |   |      >>> x.size\n",
      " |   |      30\n",
      " |   |      >>> np.prod(x.shape)\n",
      " |   |      30\n",
      " |   |  \n",
      " |   |  strides\n",
      " |   |      Tuple of bytes to step in each dimension when traversing an array.\n",
      " |   |      \n",
      " |   |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      " |   |      is::\n",
      " |   |      \n",
      " |   |          offset = sum(np.array(i) * a.strides)\n",
      " |   |      \n",
      " |   |      A more detailed explanation of strides can be found in the\n",
      " |   |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      " |   |      \n",
      " |   |      Notes\n",
      " |   |      -----\n",
      " |   |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      " |   |      \n",
      " |   |        x = np.array([[0, 1, 2, 3, 4],\n",
      " |   |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      " |   |      \n",
      " |   |      This array is stored in memory as 40 bytes, one after the other\n",
      " |   |      (known as a contiguous block of memory).  The strides of an array tell\n",
      " |   |      us how many bytes we have to skip in memory to move to the next position\n",
      " |   |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      " |   |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      " |   |      position in the next row.  As such, the strides for the array `x` will be\n",
      " |   |      ``(20, 4)``.\n",
      " |   |      \n",
      " |   |      See Also\n",
      " |   |      --------\n",
      " |   |      numpy.lib.stride_tricks.as_strided\n",
      " |   |      \n",
      " |   |      Examples\n",
      " |   |      --------\n",
      " |   |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      " |   |      >>> y\n",
      " |   |      array([[[ 0,  1,  2,  3],\n",
      " |   |              [ 4,  5,  6,  7],\n",
      " |   |              [ 8,  9, 10, 11]],\n",
      " |   |             [[12, 13, 14, 15],\n",
      " |   |              [16, 17, 18, 19],\n",
      " |   |              [20, 21, 22, 23]]])\n",
      " |   |      >>> y.strides\n",
      " |   |      (48, 16, 4)\n",
      " |   |      >>> y[1,1,1]\n",
      " |   |      17\n",
      " |   |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      " |   |      >>> offset/y.itemsize\n",
      " |   |      17\n",
      " |   |      \n",
      " |   |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      " |   |      >>> x.strides\n",
      " |   |      (32, 4, 224, 1344)\n",
      " |   |      >>> i = np.array([3,5,2,2])\n",
      " |   |      >>> offset = sum(i * x.strides)\n",
      " |   |      >>> x[3,5,2,2]\n",
      " |   |      813\n",
      " |   |      >>> offset / x.itemsize\n",
      " |   |      813\n",
      " |   |  \n",
      " |   |  ----------------------------------------------------------------------\n",
      " |   |  Data and other attributes inherited from numpy.ndarray:\n",
      " |   |  \n",
      " |   |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from AxisConcatenator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeClassifier in module sklearn.tree.tree:\n",
      "\n",
      "class DecisionTreeClassifier(BaseDecisionTree, sklearn.base.ClassifierMixin)\n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a fraction and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      BaseDecisionTree\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool\n",
      " |          Run check_array on X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cart = clf.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_cart==iris_y_test)/len(pred_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.plot_tree(clf.fit(iris_X_train, iris_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble.forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is always the same as the original\n",
      " |  input sample size but the samples are drawn with replacement if\n",
      " |  `bootstrap=True` (default).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : integer, optional (default=10)\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |         The default value of ``n_estimators`` will change from 10 in\n",
      " |         version 0.20 to 100 in version 0.22.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : integer or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=\"auto\")\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  \n",
      " |  bootstrap : boolean, optional (default=True)\n",
      " |      Whether bootstrap samples are used when building trees.\n",
      " |  \n",
      " |  oob_score : bool (default=False)\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\", \"balanced_subsample\" or     None, optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |  \n",
      " |  oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  \n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
      " |  ...                              random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      " |              max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      " |              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      " |              min_samples_leaf=1, min_samples_split=2,\n",
      " |              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      " |              oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      " |  >>> print(clf.feature_importances_)\n",
      " |  [0.14205973 0.76664038 0.0282433  0.06305659]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      abc.NewBase\n",
      " |      BaseForest\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators='warn', criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest. The\n",
      " |      class probability of a single tree is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators]\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |      \n",
      " |      n_nodes_ptr : array of size (n_estimators + 1, )\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(iris_X_train,iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_random_forest = clf.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_random_forest==iris_y_test)/len(pred_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ALFI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['range'] = (df['high']-df['low'])/df['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df['range']!=0,:]\n",
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>14146.40</td>\n",
       "      <td>14180.44</td>\n",
       "      <td>14139.74</td>\n",
       "      <td>14172.79</td>\n",
       "      <td>119232</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>14213.37</td>\n",
       "      <td>14351.86</td>\n",
       "      <td>14213.37</td>\n",
       "      <td>14350.99</td>\n",
       "      <td>234094</td>\n",
       "      <td>0.009744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>14340.92</td>\n",
       "      <td>14386.34</td>\n",
       "      <td>14257.65</td>\n",
       "      <td>14339.73</td>\n",
       "      <td>185940</td>\n",
       "      <td>0.009026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>14332.45</td>\n",
       "      <td>14332.45</td>\n",
       "      <td>14269.30</td>\n",
       "      <td>14301.69</td>\n",
       "      <td>103820</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>14320.08</td>\n",
       "      <td>14380.25</td>\n",
       "      <td>14301.68</td>\n",
       "      <td>14380.25</td>\n",
       "      <td>116740</td>\n",
       "      <td>0.005494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>14445.07</td>\n",
       "      <td>14489.08</td>\n",
       "      <td>14407.14</td>\n",
       "      <td>14444.58</td>\n",
       "      <td>170970</td>\n",
       "      <td>0.005687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>14413.57</td>\n",
       "      <td>14528.12</td>\n",
       "      <td>14384.17</td>\n",
       "      <td>14496.70</td>\n",
       "      <td>248382</td>\n",
       "      <td>0.010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>14547.88</td>\n",
       "      <td>14644.70</td>\n",
       "      <td>14462.87</td>\n",
       "      <td>14593.31</td>\n",
       "      <td>267534</td>\n",
       "      <td>0.012572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>14576.41</td>\n",
       "      <td>14909.18</td>\n",
       "      <td>14541.85</td>\n",
       "      <td>14869.40</td>\n",
       "      <td>456664</td>\n",
       "      <td>0.025260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>14838.06</td>\n",
       "      <td>14984.13</td>\n",
       "      <td>14814.75</td>\n",
       "      <td>14853.74</td>\n",
       "      <td>439036</td>\n",
       "      <td>0.011433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>14809.25</td>\n",
       "      <td>14891.51</td>\n",
       "      <td>14768.58</td>\n",
       "      <td>14866.40</td>\n",
       "      <td>300300</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>14936.63</td>\n",
       "      <td>14945.96</td>\n",
       "      <td>14803.44</td>\n",
       "      <td>14903.61</td>\n",
       "      <td>224274</td>\n",
       "      <td>0.009627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>2014-09-09</td>\n",
       "      <td>14882.86</td>\n",
       "      <td>14882.86</td>\n",
       "      <td>14686.58</td>\n",
       "      <td>14769.72</td>\n",
       "      <td>193016</td>\n",
       "      <td>0.013365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>14705.48</td>\n",
       "      <td>14729.46</td>\n",
       "      <td>14454.61</td>\n",
       "      <td>14594.27</td>\n",
       "      <td>492184</td>\n",
       "      <td>0.019015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>14569.88</td>\n",
       "      <td>14666.69</td>\n",
       "      <td>14513.60</td>\n",
       "      <td>14514.68</td>\n",
       "      <td>279994</td>\n",
       "      <td>0.010548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>14484.28</td>\n",
       "      <td>14544.64</td>\n",
       "      <td>14441.16</td>\n",
       "      <td>14535.79</td>\n",
       "      <td>225766</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>14524.99</td>\n",
       "      <td>14536.14</td>\n",
       "      <td>14239.85</td>\n",
       "      <td>14376.52</td>\n",
       "      <td>263312</td>\n",
       "      <td>0.020807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>14314.74</td>\n",
       "      <td>14352.23</td>\n",
       "      <td>14254.94</td>\n",
       "      <td>14266.98</td>\n",
       "      <td>258866</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>14306.13</td>\n",
       "      <td>14315.88</td>\n",
       "      <td>14205.00</td>\n",
       "      <td>14232.63</td>\n",
       "      <td>179376</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>14234.20</td>\n",
       "      <td>14234.20</td>\n",
       "      <td>14202.64</td>\n",
       "      <td>14215.29</td>\n",
       "      <td>175376</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>14244.88</td>\n",
       "      <td>14244.88</td>\n",
       "      <td>13991.89</td>\n",
       "      <td>13991.89</td>\n",
       "      <td>240220</td>\n",
       "      <td>0.018081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>2014-09-23</td>\n",
       "      <td>13949.05</td>\n",
       "      <td>14079.21</td>\n",
       "      <td>13949.05</td>\n",
       "      <td>14079.21</td>\n",
       "      <td>159510</td>\n",
       "      <td>0.009331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>14059.05</td>\n",
       "      <td>14117.63</td>\n",
       "      <td>14007.87</td>\n",
       "      <td>14087.99</td>\n",
       "      <td>129280</td>\n",
       "      <td>0.007836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>2014-09-25</td>\n",
       "      <td>14052.70</td>\n",
       "      <td>14119.07</td>\n",
       "      <td>14016.14</td>\n",
       "      <td>14057.08</td>\n",
       "      <td>162602</td>\n",
       "      <td>0.007344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>2014-09-26</td>\n",
       "      <td>14047.79</td>\n",
       "      <td>14077.13</td>\n",
       "      <td>14018.74</td>\n",
       "      <td>14040.36</td>\n",
       "      <td>100844</td>\n",
       "      <td>0.004165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>14035.07</td>\n",
       "      <td>14060.46</td>\n",
       "      <td>13896.49</td>\n",
       "      <td>13927.52</td>\n",
       "      <td>127762</td>\n",
       "      <td>0.011799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>13941.51</td>\n",
       "      <td>14114.80</td>\n",
       "      <td>13925.03</td>\n",
       "      <td>14001.40</td>\n",
       "      <td>146602</td>\n",
       "      <td>0.013628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>13956.42</td>\n",
       "      <td>13958.79</td>\n",
       "      <td>13767.84</td>\n",
       "      <td>13883.83</td>\n",
       "      <td>158650</td>\n",
       "      <td>0.013869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>2014-10-10</td>\n",
       "      <td>13880.17</td>\n",
       "      <td>13954.64</td>\n",
       "      <td>13719.69</td>\n",
       "      <td>13734.16</td>\n",
       "      <td>174954</td>\n",
       "      <td>0.017125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>13703.89</td>\n",
       "      <td>13847.04</td>\n",
       "      <td>13703.89</td>\n",
       "      <td>13816.18</td>\n",
       "      <td>129004</td>\n",
       "      <td>0.010446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>13402.30</td>\n",
       "      <td>13608.53</td>\n",
       "      <td>13295.42</td>\n",
       "      <td>13410.45</td>\n",
       "      <td>471854</td>\n",
       "      <td>0.023550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>13389.24</td>\n",
       "      <td>13464.58</td>\n",
       "      <td>13276.10</td>\n",
       "      <td>13291.67</td>\n",
       "      <td>468176</td>\n",
       "      <td>0.014197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>13309.41</td>\n",
       "      <td>13451.12</td>\n",
       "      <td>13207.58</td>\n",
       "      <td>13264.72</td>\n",
       "      <td>462494</td>\n",
       "      <td>0.018439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2016-12-07</td>\n",
       "      <td>13248.06</td>\n",
       "      <td>13269.90</td>\n",
       "      <td>13031.57</td>\n",
       "      <td>13223.41</td>\n",
       "      <td>609050</td>\n",
       "      <td>0.018289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>13252.95</td>\n",
       "      <td>13354.51</td>\n",
       "      <td>13058.27</td>\n",
       "      <td>13185.66</td>\n",
       "      <td>559038</td>\n",
       "      <td>0.022686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>13208.85</td>\n",
       "      <td>13435.37</td>\n",
       "      <td>13109.26</td>\n",
       "      <td>13365.56</td>\n",
       "      <td>600644</td>\n",
       "      <td>0.024876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>13376.51</td>\n",
       "      <td>13614.15</td>\n",
       "      <td>13376.51</td>\n",
       "      <td>13481.98</td>\n",
       "      <td>535902</td>\n",
       "      <td>0.017765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>2016-12-13</td>\n",
       "      <td>13443.89</td>\n",
       "      <td>13486.59</td>\n",
       "      <td>13335.24</td>\n",
       "      <td>13348.57</td>\n",
       "      <td>344290</td>\n",
       "      <td>0.011350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>13388.76</td>\n",
       "      <td>13406.11</td>\n",
       "      <td>13076.55</td>\n",
       "      <td>13098.36</td>\n",
       "      <td>490810</td>\n",
       "      <td>0.025202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>13150.49</td>\n",
       "      <td>13150.49</td>\n",
       "      <td>12908.40</td>\n",
       "      <td>13069.16</td>\n",
       "      <td>547664</td>\n",
       "      <td>0.018754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>13000.87</td>\n",
       "      <td>13132.41</td>\n",
       "      <td>12957.83</td>\n",
       "      <td>12981.72</td>\n",
       "      <td>355676</td>\n",
       "      <td>0.013473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>12937.57</td>\n",
       "      <td>12937.57</td>\n",
       "      <td>12707.91</td>\n",
       "      <td>12711.52</td>\n",
       "      <td>434470</td>\n",
       "      <td>0.018072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>12704.17</td>\n",
       "      <td>12785.17</td>\n",
       "      <td>12630.04</td>\n",
       "      <td>12743.96</td>\n",
       "      <td>384810</td>\n",
       "      <td>0.012283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>12769.43</td>\n",
       "      <td>12931.82</td>\n",
       "      <td>12741.45</td>\n",
       "      <td>12917.31</td>\n",
       "      <td>371992</td>\n",
       "      <td>0.014941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>12911.17</td>\n",
       "      <td>12959.82</td>\n",
       "      <td>12823.86</td>\n",
       "      <td>12843.94</td>\n",
       "      <td>338958</td>\n",
       "      <td>0.010602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>12853.89</td>\n",
       "      <td>12966.60</td>\n",
       "      <td>12712.56</td>\n",
       "      <td>12771.68</td>\n",
       "      <td>367218</td>\n",
       "      <td>0.019983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>12773.80</td>\n",
       "      <td>12774.30</td>\n",
       "      <td>12534.80</td>\n",
       "      <td>12714.07</td>\n",
       "      <td>407370</td>\n",
       "      <td>0.019107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>12711.54</td>\n",
       "      <td>12872.59</td>\n",
       "      <td>12641.72</td>\n",
       "      <td>12855.05</td>\n",
       "      <td>294936</td>\n",
       "      <td>0.018263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>12854.16</td>\n",
       "      <td>13014.90</td>\n",
       "      <td>12717.76</td>\n",
       "      <td>12737.00</td>\n",
       "      <td>371428</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>12668.86</td>\n",
       "      <td>12802.72</td>\n",
       "      <td>12641.23</td>\n",
       "      <td>12790.69</td>\n",
       "      <td>326160</td>\n",
       "      <td>0.012775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>12732.40</td>\n",
       "      <td>12929.20</td>\n",
       "      <td>12688.32</td>\n",
       "      <td>12863.40</td>\n",
       "      <td>409284</td>\n",
       "      <td>0.018984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>12905.86</td>\n",
       "      <td>12905.86</td>\n",
       "      <td>12644.74</td>\n",
       "      <td>12659.24</td>\n",
       "      <td>205060</td>\n",
       "      <td>0.020650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>12673.56</td>\n",
       "      <td>12714.35</td>\n",
       "      <td>12552.28</td>\n",
       "      <td>12706.65</td>\n",
       "      <td>268972</td>\n",
       "      <td>0.012912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>12700.87</td>\n",
       "      <td>12767.76</td>\n",
       "      <td>12590.79</td>\n",
       "      <td>12624.49</td>\n",
       "      <td>244678</td>\n",
       "      <td>0.014056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>12642.29</td>\n",
       "      <td>12686.92</td>\n",
       "      <td>12546.53</td>\n",
       "      <td>12549.75</td>\n",
       "      <td>207514</td>\n",
       "      <td>0.011190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>12596.87</td>\n",
       "      <td>12727.77</td>\n",
       "      <td>12566.12</td>\n",
       "      <td>12603.10</td>\n",
       "      <td>286342</td>\n",
       "      <td>0.012864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>12588.26</td>\n",
       "      <td>12889.94</td>\n",
       "      <td>12575.46</td>\n",
       "      <td>12888.50</td>\n",
       "      <td>458586</td>\n",
       "      <td>0.025007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>12938.12</td>\n",
       "      <td>13065.24</td>\n",
       "      <td>12885.26</td>\n",
       "      <td>13063.70</td>\n",
       "      <td>460252</td>\n",
       "      <td>0.013968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>13033.47</td>\n",
       "      <td>13292.69</td>\n",
       "      <td>12981.60</td>\n",
       "      <td>13292.69</td>\n",
       "      <td>468886</td>\n",
       "      <td>0.023964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>13381.05</td>\n",
       "      <td>13557.10</td>\n",
       "      <td>13241.62</td>\n",
       "      <td>13404.46</td>\n",
       "      <td>654676</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     update_date      open      high       low     close  volume     range\n",
       "1612  2014-08-20  14146.40  14180.44  14139.74  14172.79  119232  0.002878\n",
       "1613  2014-08-21  14213.37  14351.86  14213.37  14350.99  234094  0.009744\n",
       "1614  2014-08-22  14340.92  14386.34  14257.65  14339.73  185940  0.009026\n",
       "1615  2014-08-25  14332.45  14332.45  14269.30  14301.69  103820  0.004426\n",
       "1616  2014-08-26  14320.08  14380.25  14301.68  14380.25  116740  0.005494\n",
       "1617  2014-08-27  14445.07  14489.08  14407.14  14444.58  170970  0.005687\n",
       "1619  2014-08-29  14413.57  14528.12  14384.17  14496.70  248382  0.010008\n",
       "1620  2014-09-01  14547.88  14644.70  14462.87  14593.31  267534  0.012572\n",
       "1621  2014-09-02  14576.41  14909.18  14541.85  14869.40  456664  0.025260\n",
       "1622  2014-09-03  14838.06  14984.13  14814.75  14853.74  439036  0.011433\n",
       "1623  2014-09-04  14809.25  14891.51  14768.58  14866.40  300300  0.008324\n",
       "1624  2014-09-05  14936.63  14945.96  14803.44  14903.61  224274  0.009627\n",
       "1625  2014-09-09  14882.86  14882.86  14686.58  14769.72  193016  0.013365\n",
       "1626  2014-09-10  14705.48  14729.46  14454.61  14594.27  492184  0.019015\n",
       "1627  2014-09-11  14569.88  14666.69  14513.60  14514.68  279994  0.010548\n",
       "1628  2014-09-12  14484.28  14544.64  14441.16  14535.79  225766  0.007166\n",
       "1629  2014-09-15  14524.99  14536.14  14239.85  14376.52  263312  0.020807\n",
       "1630  2014-09-16  14314.74  14352.23  14254.94  14266.98  258866  0.006825\n",
       "1632  2014-09-18  14306.13  14315.88  14205.00  14232.63  179376  0.007806\n",
       "1633  2014-09-19  14234.20  14234.20  14202.64  14215.29  175376  0.002222\n",
       "1634  2014-09-22  14244.88  14244.88  13991.89  13991.89  240220  0.018081\n",
       "1635  2014-09-23  13949.05  14079.21  13949.05  14079.21  159510  0.009331\n",
       "1636  2014-09-24  14059.05  14117.63  14007.87  14087.99  129280  0.007836\n",
       "1637  2014-09-25  14052.70  14119.07  14016.14  14057.08  162602  0.007344\n",
       "1638  2014-09-26  14047.79  14077.13  14018.74  14040.36  100844  0.004165\n",
       "1639  2014-09-29  14035.07  14060.46  13896.49  13927.52  127762  0.011799\n",
       "1640  2014-09-30  13941.51  14114.80  13925.03  14001.40  146602  0.013628\n",
       "1642  2014-10-09  13956.42  13958.79  13767.84  13883.83  158650  0.013869\n",
       "1643  2014-10-10  13880.17  13954.64  13719.69  13734.16  174954  0.017125\n",
       "1644  2014-10-13  13703.89  13847.04  13703.89  13816.18  129004  0.010446\n",
       "...          ...       ...       ...       ...       ...     ...       ...\n",
       "2169  2016-12-02  13402.30  13608.53  13295.42  13410.45  471854  0.023550\n",
       "2170  2016-12-05  13389.24  13464.58  13276.10  13291.67  468176  0.014197\n",
       "2171  2016-12-06  13309.41  13451.12  13207.58  13264.72  462494  0.018439\n",
       "2172  2016-12-07  13248.06  13269.90  13031.57  13223.41  609050  0.018289\n",
       "2173  2016-12-08  13252.95  13354.51  13058.27  13185.66  559038  0.022686\n",
       "2174  2016-12-09  13208.85  13435.37  13109.26  13365.56  600644  0.024876\n",
       "2175  2016-12-12  13376.51  13614.15  13376.51  13481.98  535902  0.017765\n",
       "2176  2016-12-13  13443.89  13486.59  13335.24  13348.57  344290  0.011350\n",
       "2177  2016-12-14  13388.76  13406.11  13076.55  13098.36  490810  0.025202\n",
       "2178  2016-12-15  13150.49  13150.49  12908.40  13069.16  547664  0.018754\n",
       "2179  2016-12-16  13000.87  13132.41  12957.83  12981.72  355676  0.013473\n",
       "2180  2016-12-19  12937.57  12937.57  12707.91  12711.52  434470  0.018072\n",
       "2181  2016-12-20  12704.17  12785.17  12630.04  12743.96  384810  0.012283\n",
       "2182  2016-12-21  12769.43  12931.82  12741.45  12917.31  371992  0.014941\n",
       "2183  2016-12-22  12911.17  12959.82  12823.86  12843.94  338958  0.010602\n",
       "2184  2016-12-23  12853.89  12966.60  12712.56  12771.68  367218  0.019983\n",
       "2185  2016-12-26  12773.80  12774.30  12534.80  12714.07  407370  0.019107\n",
       "2186  2016-12-27  12711.54  12872.59  12641.72  12855.05  294936  0.018263\n",
       "2187  2016-12-28  12854.16  13014.90  12717.76  12737.00  371428  0.023364\n",
       "2188  2016-12-29  12668.86  12802.72  12641.23  12790.69  326160  0.012775\n",
       "2189  2016-12-30  12732.40  12929.20  12688.32  12863.40  409284  0.018984\n",
       "2190  2017-01-03  12905.86  12905.86  12644.74  12659.24  205060  0.020650\n",
       "2191  2017-01-04  12673.56  12714.35  12552.28  12706.65  268972  0.012912\n",
       "2192  2017-01-05  12700.87  12767.76  12590.79  12624.49  244678  0.014056\n",
       "2193  2017-01-06  12642.29  12686.92  12546.53  12549.75  207514  0.011190\n",
       "2194  2017-01-09  12596.87  12727.77  12566.12  12603.10  286342  0.012864\n",
       "2195  2017-01-10  12588.26  12889.94  12575.46  12888.50  458586  0.025007\n",
       "2196  2017-01-11  12938.12  13065.24  12885.26  13063.70  460252  0.013968\n",
       "2197  2017-01-12  13033.47  13292.69  12981.60  13292.69  468886  0.023964\n",
       "2198  2017-01-13  13381.05  13557.10  13241.62  13404.46  654676  0.023825\n",
       "\n",
       "[582 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df['volume'])\n",
    "y = np.array(df['range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x>=0.012 else -1,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,1)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57560137])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==-1)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[indices[:-100]]\n",
    "y_train = y[indices[:-100]]\n",
    "X_test = X[indices[-100:]]\n",
    "y_test = y[indices[-100:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_cart = clf.predict(X_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_cart==y_test)/pred_cart.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1,\n",
       "       -1,  1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1,\n",
       "       -1,  1, -1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1,  1, -1,\n",
       "       -1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
